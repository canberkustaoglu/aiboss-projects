{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ae21a539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.0-cp310-cp310-win_amd64.whl (9.2 MB)\n",
      "Collecting patsy>=0.5.2\n",
      "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages (from statsmodels) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages (from statsmodels) (2.0.3)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages (from statsmodels) (21.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in c:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages (from statsmodels) (1.9.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages (from packaging>=21.3->statsmodels) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: six in c:\\users\\asus\\anaconda3\\envs\\notebook\\lib\\site-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-0.5.3 statsmodels-0.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "150e7603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39138f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "veriler = pd.read_csv('veriler.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae10115",
   "metadata": {},
   "source": [
    "## veriler csv dosyasını pickle'a çevirip inceleyeceğim. neden? daha hızlı ve daha managable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b3dbe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "veriler.to_pickle('veriler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f84738",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('veriler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80ab8e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ulke</th>\n",
       "      <th>boy</th>\n",
       "      <th>kilo</th>\n",
       "      <th>yas</th>\n",
       "      <th>cinsiyet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr</td>\n",
       "      <td>130</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr</td>\n",
       "      <td>125</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tr</td>\n",
       "      <td>135</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tr</td>\n",
       "      <td>133</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tr</td>\n",
       "      <td>129</td>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tr</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tr</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>25</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tr</td>\n",
       "      <td>175</td>\n",
       "      <td>90</td>\n",
       "      <td>35</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tr</td>\n",
       "      <td>177</td>\n",
       "      <td>60</td>\n",
       "      <td>22</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>us</td>\n",
       "      <td>185</td>\n",
       "      <td>105</td>\n",
       "      <td>33</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>us</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>27</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>us</td>\n",
       "      <td>155</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>us</td>\n",
       "      <td>160</td>\n",
       "      <td>58</td>\n",
       "      <td>39</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>us</td>\n",
       "      <td>162</td>\n",
       "      <td>59</td>\n",
       "      <td>41</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>us</td>\n",
       "      <td>167</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fr</td>\n",
       "      <td>174</td>\n",
       "      <td>70</td>\n",
       "      <td>47</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fr</td>\n",
       "      <td>193</td>\n",
       "      <td>90</td>\n",
       "      <td>23</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fr</td>\n",
       "      <td>187</td>\n",
       "      <td>80</td>\n",
       "      <td>27</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fr</td>\n",
       "      <td>183</td>\n",
       "      <td>88</td>\n",
       "      <td>28</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fr</td>\n",
       "      <td>159</td>\n",
       "      <td>40</td>\n",
       "      <td>29</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>fr</td>\n",
       "      <td>164</td>\n",
       "      <td>66</td>\n",
       "      <td>32</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fr</td>\n",
       "      <td>166</td>\n",
       "      <td>56</td>\n",
       "      <td>42</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ulke  boy  kilo  yas cinsiyet\n",
       "0    tr  130    30   10        e\n",
       "1    tr  125    36   11        e\n",
       "2    tr  135    34   10        k\n",
       "3    tr  133    30    9        k\n",
       "4    tr  129    38   12        e\n",
       "5    tr  180    90   30        e\n",
       "6    tr  190    80   25        e\n",
       "7    tr  175    90   35        e\n",
       "8    tr  177    60   22        k\n",
       "9    us  185   105   33        e\n",
       "10   us  165    55   27        k\n",
       "11   us  155    50   44        k\n",
       "12   us  160    58   39        k\n",
       "13   us  162    59   41        k\n",
       "14   us  167    62   55        k\n",
       "15   fr  174    70   47        e\n",
       "16   fr  193    90   23        e\n",
       "17   fr  187    80   27        e\n",
       "18   fr  183    88   28        e\n",
       "19   fr  159    40   29        k\n",
       "20   fr  164    66   32        k\n",
       "21   fr  166    56   42        k"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f14ba17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22 entries, 0 to 21\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   ulke      22 non-null     object\n",
      " 1   boy       22 non-null     int64 \n",
      " 2   kilo      22 non-null     int64 \n",
      " 3   yas       22 non-null     int64 \n",
      " 4   cinsiyet  22 non-null     object\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 1008.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d54d16a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "897efd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boy</th>\n",
       "      <td>22.0</td>\n",
       "      <td>163.363636</td>\n",
       "      <td>21.077059</td>\n",
       "      <td>125.0</td>\n",
       "      <td>156.00</td>\n",
       "      <td>165.5</td>\n",
       "      <td>179.25</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kilo</th>\n",
       "      <td>22.0</td>\n",
       "      <td>62.136364</td>\n",
       "      <td>22.286651</td>\n",
       "      <td>30.0</td>\n",
       "      <td>42.50</td>\n",
       "      <td>59.5</td>\n",
       "      <td>80.00</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yas</th>\n",
       "      <td>22.0</td>\n",
       "      <td>28.681818</td>\n",
       "      <td>12.988590</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.25</td>\n",
       "      <td>28.5</td>\n",
       "      <td>38.00</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count        mean        std    min     25%    50%     75%    max\n",
       "boy    22.0  163.363636  21.077059  125.0  156.00  165.5  179.25  193.0\n",
       "kilo   22.0   62.136364  22.286651   30.0   42.50   59.5   80.00  105.0\n",
       "yas    22.0   28.681818  12.988590    9.0   22.25   28.5   38.00   55.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a2d8b4",
   "metadata": {},
   "source": [
    "### missing value problemi var mı inceleme yapalım ve ona göre hareket edelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1916100c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[data.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ab8de7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ulke        0\n",
       "boy         0\n",
       "kilo        0\n",
       "yas         0\n",
       "cinsiyet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59393004",
   "metadata": {},
   "source": [
    "#### sıkıntı yok devam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a8a7490",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ulke        object\n",
       "boy          int64\n",
       "kilo         int64\n",
       "yas          int64\n",
       "cinsiyet    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "def97e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_numeric = data.select_dtypes(include=['int'])\n",
    "#data_numeric.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8f751e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a8566dc",
   "metadata": {},
   "source": [
    "### verilde cinsiyet ve ülke columnuna one-hot encoding uygulayalım, daha sonra da cinsiyet columnunu atalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06d8c88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2edda230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ulke', 'cinsiyet']\n"
     ]
    }
   ],
   "source": [
    "# define the categorical columns to exclude from normalization\n",
    "categorical_columns = data.select_dtypes(include = 'object').columns.to_list()\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f3db88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boy', 'kilo', 'yas']\n"
     ]
    }
   ],
   "source": [
    "categorical = categorical_columns\n",
    "\n",
    "# define the columns to include in normalization\n",
    "columns_to_normalize = [col for col in data.columns if col not in categorical]\n",
    "print(columns_to_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a69e574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1071b449",
   "metadata": {},
   "source": [
    "# get the data to be scaled\n",
    "df_continious = data[columns_to_normalize]\n",
    "\n",
    "min_max_columns_names = list(df_continious.columns)\n",
    "all_scalers = {}\n",
    "\n",
    "for column_name in min_max_columns_names:\n",
    "    all_scalers[column_name] = MinMaxScaler().fit(df_continious[[column_name]])\n",
    "    \n",
    "# -1 ve 1 arasında korelasyonun da gözükebileceği biçimde bir data normlizaston\n",
    "çakalım\n",
    "for column_name, scaler in  all_scalers.items():\n",
    "    df_continious[column_name] = scaler.transform(df_continious[[column_name]].values.reshape(-1,1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c846958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_7784\\689206453.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_continuous[column_name] = scaler.transform(df_continuous[[column_name]].values.reshape(-1, 1))\n",
      "C:\\Users\\Asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_7784\\689206453.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_continuous[column_name] = scaler.transform(df_continuous[[column_name]].values.reshape(-1, 1))\n",
      "C:\\Users\\Asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_7784\\689206453.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_continuous[column_name] = scaler.transform(df_continuous[[column_name]].values.reshape(-1, 1))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df_continuous = data[columns_to_normalize]\n",
    "min_max_columns_names = list(df_continuous.columns)\n",
    "all_scalers = {}\n",
    "\n",
    "for column_name in min_max_columns_names:\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_continuous[[column_name]])\n",
    "    all_scalers[column_name] = scaler\n",
    "    \n",
    "for column_name, scaler in all_scalers.items():\n",
    "    df_continuous[column_name] = scaler.transform(df_continuous[[column_name]].values.reshape(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "049a7a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ulke</th>\n",
       "      <th>boy</th>\n",
       "      <th>kilo</th>\n",
       "      <th>yas</th>\n",
       "      <th>cinsiyet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tr</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tr</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tr</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tr</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tr</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tr</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tr</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>us</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>us</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>us</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>us</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>us</td>\n",
       "      <td>0.544118</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>us</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fr</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fr</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fr</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fr</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fr</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>fr</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fr</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ulke       boy      kilo       yas cinsiyet\n",
       "0    tr  0.073529  0.000000  0.021739        e\n",
       "1    tr  0.000000  0.080000  0.043478        e\n",
       "2    tr  0.147059  0.053333  0.021739        k\n",
       "3    tr  0.117647  0.000000  0.000000        k\n",
       "4    tr  0.058824  0.106667  0.065217        e\n",
       "5    tr  0.808824  0.800000  0.456522        e\n",
       "6    tr  0.955882  0.666667  0.347826        e\n",
       "7    tr  0.735294  0.800000  0.565217        e\n",
       "8    tr  0.764706  0.400000  0.282609        k\n",
       "9    us  0.882353  1.000000  0.521739        e\n",
       "10   us  0.588235  0.333333  0.391304        k\n",
       "11   us  0.441176  0.266667  0.760870        k\n",
       "12   us  0.514706  0.373333  0.652174        k\n",
       "13   us  0.544118  0.386667  0.695652        k\n",
       "14   us  0.617647  0.426667  1.000000        k\n",
       "15   fr  0.720588  0.533333  0.826087        e\n",
       "16   fr  1.000000  0.800000  0.304348        e\n",
       "17   fr  0.911765  0.666667  0.391304        e\n",
       "18   fr  0.852941  0.773333  0.413043        e\n",
       "19   fr  0.500000  0.133333  0.434783        k\n",
       "20   fr  0.573529  0.480000  0.500000        k\n",
       "21   fr  0.602941  0.346667  0.717391        k"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data = pd.concat([df_continuous,data[categorical]], axis= 1)\n",
    "normalized_data = normalized_data.reindex(data.columns, axis = 1)\n",
    "normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eef09aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96f905e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ulke</th>\n",
       "      <th>cinsiyet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tr</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tr</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tr</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ulke cinsiyet\n",
       "0   tr        e\n",
       "1   tr        e\n",
       "2   tr        k\n",
       "3   tr        k\n",
       "4   tr        e"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[categorical].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3be32ff",
   "metadata": {},
   "source": [
    "## kendime not: bu işlemden önce verideki diğer featurelar üzerinde data normalization uygulasaydım ve distribution based bir yaklaşımdan uzak kalsam daha güzel sonuçlarla karşılaşabilirim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e765758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cinsiyet_e</th>\n",
       "      <th>cinsiyet_k</th>\n",
       "      <th>ulke_fr</th>\n",
       "      <th>ulke_tr</th>\n",
       "      <th>ulke_us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cinsiyet_e  cinsiyet_k  ulke_fr  ulke_tr  ulke_us\n",
       "0         1.0         0.0      0.0      1.0      0.0\n",
       "1         1.0         0.0      0.0      1.0      0.0\n",
       "2         0.0         1.0      0.0      1.0      0.0\n",
       "3         0.0         1.0      0.0      1.0      0.0\n",
       "4         1.0         0.0      0.0      1.0      0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_encode = ['cinsiyet', 'ulke']\n",
    "\n",
    "# one-hot encode the selected columns and append them to your original dataframe\n",
    "encoded_cols = pd.get_dummies(data[cols_to_encode], dtype = np.float32)\n",
    "df = pd.concat([data[categorical], encoded_cols],axis=1)\n",
    "\n",
    "# drop the original columns that were one-hot encoded\n",
    "df.drop(cols_to_encode, axis=1,inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb9e69b",
   "metadata": {},
   "source": [
    "# şu anda, elimizde normalize edilmiş veri ve one hot encoding atılmış yeni feature'lar var. birleştirelim ve bir regression işlemi uygulayalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2654349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# float veri oluşturan columnları hazırlayalım\n",
    "float_columns = normalized_data.select_dtypes(include=['float']).columns\n",
    "float_data = normalized_data[float_columns]\n",
    "\n",
    "normalized_data = pd.concat([float_data, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d53b085",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boy</th>\n",
       "      <th>kilo</th>\n",
       "      <th>yas</th>\n",
       "      <th>cinsiyet_e</th>\n",
       "      <th>cinsiyet_k</th>\n",
       "      <th>ulke_fr</th>\n",
       "      <th>ulke_tr</th>\n",
       "      <th>ulke_us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.544118</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         boy      kilo       yas  cinsiyet_e  cinsiyet_k  ulke_fr  ulke_tr  \\\n",
       "0   0.073529  0.000000  0.021739         1.0         0.0      0.0      1.0   \n",
       "1   0.000000  0.080000  0.043478         1.0         0.0      0.0      1.0   \n",
       "2   0.147059  0.053333  0.021739         0.0         1.0      0.0      1.0   \n",
       "3   0.117647  0.000000  0.000000         0.0         1.0      0.0      1.0   \n",
       "4   0.058824  0.106667  0.065217         1.0         0.0      0.0      1.0   \n",
       "5   0.808824  0.800000  0.456522         1.0         0.0      0.0      1.0   \n",
       "6   0.955882  0.666667  0.347826         1.0         0.0      0.0      1.0   \n",
       "7   0.735294  0.800000  0.565217         1.0         0.0      0.0      1.0   \n",
       "8   0.764706  0.400000  0.282609         0.0         1.0      0.0      1.0   \n",
       "9   0.882353  1.000000  0.521739         1.0         0.0      0.0      0.0   \n",
       "10  0.588235  0.333333  0.391304         0.0         1.0      0.0      0.0   \n",
       "11  0.441176  0.266667  0.760870         0.0         1.0      0.0      0.0   \n",
       "12  0.514706  0.373333  0.652174         0.0         1.0      0.0      0.0   \n",
       "13  0.544118  0.386667  0.695652         0.0         1.0      0.0      0.0   \n",
       "14  0.617647  0.426667  1.000000         0.0         1.0      0.0      0.0   \n",
       "15  0.720588  0.533333  0.826087         1.0         0.0      1.0      0.0   \n",
       "16  1.000000  0.800000  0.304348         1.0         0.0      1.0      0.0   \n",
       "17  0.911765  0.666667  0.391304         1.0         0.0      1.0      0.0   \n",
       "18  0.852941  0.773333  0.413043         1.0         0.0      1.0      0.0   \n",
       "19  0.500000  0.133333  0.434783         0.0         1.0      1.0      0.0   \n",
       "20  0.573529  0.480000  0.500000         0.0         1.0      1.0      0.0   \n",
       "21  0.602941  0.346667  0.717391         0.0         1.0      1.0      0.0   \n",
       "\n",
       "    ulke_us  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "5       0.0  \n",
       "6       0.0  \n",
       "7       0.0  \n",
       "8       0.0  \n",
       "9       1.0  \n",
       "10      1.0  \n",
       "11      1.0  \n",
       "12      1.0  \n",
       "13      1.0  \n",
       "14      1.0  \n",
       "15      0.0  \n",
       "16      0.0  \n",
       "17      0.0  \n",
       "18      0.0  \n",
       "19      0.0  \n",
       "20      0.0  \n",
       "21      0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb20246d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAAsTAAALEwEAmpwYAAATW0lEQVR4nO3df4xlZX3H8feXoZTFSnHdcUNnFwe8q6b9Q0rHDaltqlJaoI1Lk4ZAWt0a4jYWJmPTRtE/NE1qQo2tHacJyaobIWn5YdVCmk2pJbGmSVFmEZGferuVsiPsDqwF0lkgu3z7x5wlk2XWhXtn7nf2nvcrIXvPc87c+SzLfPLw7LnnicxEkjR4p1QHkKS2soAlqYgFLElFLGBJKmIBS1KRU6sDAGzYsCHHx8erY0jSituzZ89TmTm63Lk1UcDj4+PMzs5Wx5CkFRcRjx3vnEsQklRkTcyANXgzMzN0u93qGAM3NzcHwNjYWHGSGp1Oh8nJyeoYaljAapVDhw5VR5BeZgG3VFtnQVNTUwBMT08XJ5FcA5akMhawJBWxgCWpiAUsSUUsYEkqYgFLUhELWJKKWMCSVMQClqQiFrAkFbGAJanICQs4InZFxIGIeGDJ2PkRcXdE3BcRsxGxtRmPiPh8RHQj4v6IuGA1w0vSyezVzIC/DFxyzNhngL/IzPOBTzbHAJcCW5p/dgA3rEhKSRpCJyzgzPwWcPDYYeDM5vXPAz9uXm8DbspFdwNnRcTZKxVWkoZJr4+j/AhwZ0R8lsUS/9VmfAx4fMl1+5qxJ459g4jYweIsmXPOOafHGP1p60PJ2+zon/fRx1KqHdbqg+h7LeAPA3+amV+NiCuALwG/+VreIDN3AjsBJiYmssccfel2u9z3wMMcOWN9xbdXgVNeXPxPbc/e/cVJNCgjC8f+D/za0WsBbweOTiG+AnyxeT0HbF5y3aZmbM06csZ6Dr39suoYklbJukd2V0c4rl5vQ/sx8BvN6/cCP2xe3wF8oLkb4kLgmcx8xfKDJOlVzIAj4mbg3cCGiNgHfAr4EDAdEacCz9Os5QK7gcuALrAAfHAVMkvSUDhhAWfmVcc59SvLXJvANf2GkqQ28JNwklTEApakIhawJBWxgCWpiAUsSUUsYEkqYgFLUhELWJKKWMCSVMQClqQivT4NbSjMzc0xsvDMmn5akqT+jCw8zdzc4eoYy3IGLElFWj0DHhsb48kXTvV5wNIQW/fIbsbGNlbHWJYzYEkq0tO29M34ZEQ8EhEPRsRnlox/vNmW/tGI+O3VCC1Jw+DVLEF8Gfg74KajAxHxHhZ3QH5HZr4QEW9qxn8RuBL4JeAXgH+LiLdm5pGVDi5JJ7tet6X/MHB9Zr7QXHOgGd8G3JKZL2Tmf7O4M8bWFcwrSUOj1zXgtwK/HhHfjoh/j4h3NuPH25ZeknSMXu+COBVYD1wIvBO4LSLOey1vEBE7aPaSO+ecc3qMIUknr15nwPuAr+Wi7wAvARt4DdvSZ+bOzJzIzInR0dEeY0jSyavXAv4n4D0AEfFW4DTgKRa3pb8yIn42Is4FtgDfWYGckjR0et2Wfhewq7k17UVge7Mj8oMRcRvwEHAYuGat3wExsnDQjyK3yCnPPwvAS6efWZxEgzKycBBYmx/E6Gdb+j88zvWfBj7dT6hB6XQ61RE0YN3ucwB0zlubP5BaDRvX7M96qz+KPDk5WR1BAzY1NQXA9PR0cRLJjyJLUhkLWJKKWMCSVMQClqQiFrAkFbGAJamIBSxJRSxgSSpiAUtSEQtYkopYwJJUxAKWpCIWsCQVsYAlqcgJCzgidkXEgebh68ee+7OIyIjY0BxHRHw+IroRcX9EXLAaoSVpGLyaGfCXgUuOHYyIzcBvAf+zZPhSFrch2sLihps39B9RkobTCQs4M78FHFzm1OeAjwK5ZGwbcFOzWefdwFkRcfaKJJWkIdPTGnBEbAPmMvN7x5waAx5fcryvGVvuPXZExGxEzM7Pz/cSQ5JOaq+5gCPiDOATwCf7+cZuSy+p7XrZE+4twLnA9yICYBNwb0RsBeaAzUuu3dSMSZKO8ZpnwJn5/cx8U2aOZ+Y4i8sMF2Tmk8AdwAeauyEuBJ7JzCdWNrIkDYdXcxvazcB/Am+LiH0RcfVPuXw3sBfoAl8A/mRFUkrSEDrhEkRmXnWC8+NLXidwTf+xJGn4+Uk4SSpiAUtSEQtYkopYwJJUxAKWpCIWsCQVsYAlqYgFLElFLGBJKmIBS1IRC1iSivTyOEoNgZmZGbrdbnWMgTv6e56amipOUqPT6TA5OVkdQw0LWK2ybt266gjSyyzglnIWJNVzDViSiljAklQkFp+hXhwiYh54rDqHWmMD8FR1CLXGmzNz2Z2H10QBS4MUEbOZOVGdQ3IJQpKKWMCSVMQCVhvtrA4ggWvAklTGGbAkFbGAJamIBaxWiYhLIuLRiOhGxHXVedRurgGrNSJiBPgBcDGwD7gHuCozHyoNptZyBqw22Qp0M3NvZr4I3AJsK86kFrOA1SZjwONLjvc1Y1IJC1iSiljAapM5YPOS403NmFTCAlab3ANsiYhzI+I04ErgjuJMajF3xFBrZObhiLgWuBMYAXZl5oPFsdRi3oYmSUVcgpCkIhawJBWxgCWpiAUsSUUsYEkqYgFLUhELWJKKWMCSVMQClqQiFrAkFbGAJanImngYz4YNG3J8fLw6hiStuD179jyVmaPLnVsTBTw+Ps7s7Gx1DElacRHx2PHOuQQhSUXWxAxYgzczM0O3262OMXBzc4sbYIyNtXMruE6nw+TkZHUMNSxgtcqhQ4eqI0gvs4Bbqq2zoKmpKQCmp6eLk0ivYg04InZFxIGIeGDJ2PqI+EZE/LD59Q3NeETE5yOiGxH3R8QFqxlekk5mr+Yv4b4MXHLM2HXAXZm5BbirOQa4FNjS/LMDuGFlYkrS8DlhAWfmt4CDxwxvA25sXt8IXL5k/KZcdDdwVkScvUJZJWmo9Hob2sbMfKJ5/SSwsXk9Bjy+5Lp9zdgrRMSOiJiNiNn5+fkeY0jSyavv+4BzcVvl17y1cmbuzMyJzJwYHV32QyKSNNR6LeD9R5cWml8PNONzwOYl121qxiRJx+i1gO8AtjevtwO3Lxn/QHM3xIXAM0uWKiRJS5zwPuCIuBl4N7AhIvYBnwKuB26LiKuBx4Armst3A5cBXWAB+OAqZJakoXDCAs7Mq45z6qJlrk3gmn5DSVIb+DAeSSpiAUtSEQtYkopYwJJUxAKWpCIWsCQVsYAlqYgFLElFLGBJKmIBS1IRC1iSiljAklTEApakIhawJBWxgCWpyAmfBzzMZmZm6Ha71TE0QEf/vKempoqTaJA6nQ6Tk5PVMV6h1QXc7Xa574GHOXLG+uooGpBTXlzcP3bP3v3FSTQoIwsHqyMcV6sLGODIGes59PbLqmNIWiXrHtldHeG4ei7giHgbcOuSofOATwJnAR8C5pvxT2Tm2v03IElFei7gzHwUOB8gIkZY3H7+6yxuxPm5zPzsSgSUpGG1UndBXAT8V2Y+tkLvJ0lDb6UK+Erg5iXH10bE/RGxKyLesNwXRMSOiJiNiNn5+fnlLpGkodZ3AUfEacD7gK80QzcAb2FxeeIJ4K+X+7rM3JmZE5k5MTo62m8MSTrprMQM+FLg3szcD5CZ+zPzSGa+BHwB2LoC30OShs5KFPBVLFl+iIizl5z7PeCBFfgekjR0+roPOCJeB1wM/PGS4c9ExPlAAj865pwkqdFXAWfm/wFvPGbs/X0lkqSW8GE8klTEApakIhawJBWxgCWpiAUsSUUsYEkqYgFLUhELWJKKWMCSVMQClqQird4Tbm5ujpGFZ9b0nlGS+jOy8DRzc4erYyzLGbAkFWn1DHhsbIwnXzjVXZGlIbbukd2MjW2sjrEsZ8CSVMQClqQiFrAkFbGAJamIBSxJRfrdE+5HwHPAEeBwZk5ExHrgVmCcxT3hrsjMn/QXU5KGz0rMgN+Tmedn5kRzfB1wV2ZuAe5qjiVJx1iNJYhtwI3N6xuBy1fhe0jSSa/fAk7gXyNiT0TsaMY2ZuYTzesngWXvgI6IHRExGxGz8/PzfcaQpJNPv5+E+7XMnIuINwHfiIhHlp7MzIyIXO4LM3MnsBNgYmJi2WskaZj1NQPOzLnm1wPA14GtwP6IOBug+fVAvyElaRj1XMAR8bqIeP3R18BvAQ8AdwDbm8u2A7f3G1KShlE/SxAbga9HxNH3+YfM/JeIuAe4LSKuBh4Drug/piQNn54LODP3Au9YZvxp4KJ+QklSG/hJOEkq0urnAQOMLBx0R4wWOeX5ZwF46fQzi5NoUEYWDnKcu2HLtbqAO51OdQQNWLf7HACd89bmD6RWw8Y1+7Pe6gKenJysjqABm5qaAmB6ero4ieQasCSVsYAlqYgFLElFLGBJKmIBS1IRC1iSiljAklTEApakIhawJBWxgCWpSKs/itxmMzMzdLvd6hgDd/T3fPQjyW3T6XT8CP4aYgGrVdatW1cdQXqZBdxSzoKkeq4BS1IRC1iSikRmVmcgIuZZ3MBTGoQNwFPVIdQab87M0eVOrIkClgYpImYzc6I6h+QShCQVsYAlqYgFrDbaWR1AAteAJamMM2BJKmIBS1IRC1itEhGXRMSjEdGNiOuq86jdXANWa0TECPAD4GJgH3APcFVmPlQaTK3lDFhtshXoZubezHwRuAXYVpxJLWYBq03GgMeXHO9rxqQSFrAkFbGA1SZzwOYlx5uaMamEBaw2uQfYEhHnRsRpwJXAHcWZ1GLuiKHWyMzDEXEtcCcwAuzKzAeLY6nFvA1Nkoq4BCFJRSxgSSpiAUtSEQtYkopYwJJUxAKWpCIWsCQVsYAlqYgFLElFLGBJKmIBS1KRNfEwng0bNuT4+Hh1DElacXv27HkqM0eXO7cmCnh8fJzZ2dnqGJK04iLiseOdcwlCkoqsiRmwBm9mZoZut1sdY+Dm5hY3wBgba+dWcJ1Oh8nJyeoYaljAapVDhw5VR5BeZgG3VFtnQVNTUwBMT08XJ5FcA5akMhawJBWxgCWpiAUsSUUsYEkqYgFLUhELWJKKWMCSVMQClqQiFrAkFbGAJamIBSxJRSxgSSpiAUtSEQtYkopYwJJUxAKWpCIWsCQVsYAlqYgFLElFLGBJKtJ3AUfESER8NyL+uTk+NyK+HRHdiLg1Ik7rP6YkDZ+VmAFPAQ8vOf4r4HOZ2QF+Aly9At9DkoZOXwUcEZuA3wG+2BwH8F7gH5tLbgQu7+d7SNKw6ncG/LfAR4GXmuM3Av+bmYeb433A2HJfGBE7ImI2Imbn5+f7jCFJJ5+eCzgifhc4kJl7evn6zNyZmROZOTE6OtprDEk6aZ3ax9e+C3hfRFwGnA6cCUwDZ0XEqc0seBMw139MSRo+PRdwZn4c+DhARLwb+PPM/IOI+Arw+8AtwHbg9v5jro6ZmRm63W51DA3Q0T/vqamp4iQapE6nw+TkZHWMV+hnBnw8HwNuiYi/BL4LfGkVvseK6Ha73PfAwxw5Y311FA3IKS8mAHv27i9OokEZWThYHeG4VqSAM/ObwDeb13uBrSvxvoNw5Iz1HHr7ZdUxJK2SdY/sro5wXH4STpKKWMCSVMQClqQiFrAkFbGAJamIBSxJRSxgSSpiAUtSEQtYkopYwJJUxAKWpCIWsCQVsYAlqYgFLElFVuN5wCeNubk5RhaeWdOPq5PUn5GFp5mbO3ziCws4A5akIq2eAY+NjfHkC6f6QHZpiK17ZDdjYxurYyzLGbAkFbGAJamIBSxJRSxgSSpiAUtSEQtYkopYwJJUxAKWpCKt/iAGwMjCQT+K3CKnPP8sAC+dfmZxEg3KyMJBYG1+EKPnAo6IzcBNLP7OEtiZmdMRsR64FRgHfgRckZk/6T/qyut0OtURNGDd7nMAdM5bmz+QWg0b1+zPemRmb18YcTZwdmbeGxGvB/YAlwN/BBzMzOsj4jrgDZn5sZ/2XhMTEzk7O9tTDum1mJqaAmB6ero4idoiIvZk5sRy53peA87MJzLz3ub1c8DDwBiwDbixuexGFktZknSMFflLuIgYB34Z+DawMTOfaE49yVpdfJGkYn0XcET8HPBV4COZ+ezSc7m4vrHsGkdE7IiI2YiYnZ+f7zeGJJ10+irgiPgZFsv37zPza83w/mZ9+Og68YHlvjYzd2bmRGZOjI6O9hNDkk5KPRdwRATwJeDhzPybJafuALY3r7cDt/ceT5KGVz/3Ab8LeD/w/Yi4rxn7BHA9cFtEXA08BlzRV0JJGlI9F3Bm/gcQxzl9Ua/vK0lt4UeRJamIBSxJRSxgSSpiAUtSEQtYkopYwJJUxAKWpCIWsCQVsYAlqYgFLElFLGBJKmIBS1IRC1iSirR+W/q2mpmZodvtVscYuKO/56Obc7ZNp9NhcnKyOoYaFrBaZd26ddURpJdZwC3lLEiq5xqwJBWxgCWpSCzuHF8cImKexf3jpEHYADxVHUKt8ebMXHbr9zVRwNIgRcRsZk5U55BcgpCkIhawJBWxgNVGO6sDSOAasCSVcQYsSUUsYEkqYgGrVSLikoh4NCK6EXFddR61m2vAao2IGAF+AFwM7APuAa7KzIdKg6m1nAGrTbYC3czcm5kvArcA24ozqcUsYLXJGPD4kuN9zZhUwgKWpCIWsNpkDti85HhTMyaVsIDVJvcAWyLi3Ig4DbgSuKM4k1rMHTHUGpl5OCKuBe4ERoBdmflgcSy1mLehSVIRlyAkqYgFLElFLGBJKmIBS1IRC1iSiljAklTEApakIv8PFlKdubEAacwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Outlier Analysis\n",
    "fig, axs = plt.subplots(3, figsize = (5,5))\n",
    "plt1 = sns.boxplot(data['boy'], ax = axs[0])\n",
    "plt2 = sns.boxplot(data['kilo'], ax = axs[1])\n",
    "plt3 = sns.boxplot(data['yas'], ax = axs[2])\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c91b9a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\seaborn\\axisgrid.py:118: UserWarning: The figure layout has changed to tight\n",
      "  self._figure.tight_layout(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# yaşa göre boy ve kilo dağılımı\n",
    "sns.pairplot(data, x_vars=['boy', 'kilo'], y_vars='yas', height=4, aspect=1, kind='scatter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63e0d776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yas\n",
       "10    2\n",
       "27    2\n",
       "39    1\n",
       "32    1\n",
       "29    1\n",
       "28    1\n",
       "23    1\n",
       "47    1\n",
       "55    1\n",
       "41    1\n",
       "44    1\n",
       "11    1\n",
       "33    1\n",
       "22    1\n",
       "35    1\n",
       "25    1\n",
       "30    1\n",
       "12    1\n",
       "9     1\n",
       "42    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.yas.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3e4e6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['boy', 'kilo', 'yas', 'cinsiyet_e', 'cinsiyet_k', 'ulke_fr', 'ulke_tr', 'ulke_us']\n"
     ]
    }
   ],
   "source": [
    "print(list(normalized_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21d9f47c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## outlier olarak bi fonksiyon var elimde ama kullanmaya üşendim görülen genel olarak veride bir outlier durum olmadığı"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadf5c1a",
   "metadata": {},
   "source": [
    "## korelasyon incelemesi yapalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47dee97c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1cda9_row0_col0, #T_1cda9_row1_col1, #T_1cda9_row2_col2, #T_1cda9_row3_col3, #T_1cda9_row3_col4, #T_1cda9_row4_col3, #T_1cda9_row4_col4, #T_1cda9_row5_col5, #T_1cda9_row6_col6, #T_1cda9_row7_col7 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1cda9_row0_col1, #T_1cda9_row1_col0 {\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1cda9_row0_col2, #T_1cda9_row2_col1, #T_1cda9_row5_col7 {\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1cda9_row0_col3, #T_1cda9_row0_col4 {\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1cda9_row0_col5 {\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1cda9_row0_col6 {\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1cda9_row0_col7, #T_1cda9_row3_col5, #T_1cda9_row3_col6, #T_1cda9_row4_col5, #T_1cda9_row4_col6, #T_1cda9_row5_col2, #T_1cda9_row5_col3, #T_1cda9_row5_col4, #T_1cda9_row7_col0, #T_1cda9_row7_col1 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1cda9_row1_col2 {\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1cda9_row1_col3, #T_1cda9_row1_col4, #T_1cda9_row7_col2 {\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1cda9_row1_col5, #T_1cda9_row2_col3, #T_1cda9_row2_col4 {\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1cda9_row1_col6 {\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1cda9_row1_col7 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1cda9_row2_col0 {\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1cda9_row2_col5 {\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1cda9_row2_col6 {\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1cda9_row2_col7 {\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1cda9_row3_col0, #T_1cda9_row4_col0 {\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1cda9_row3_col1, #T_1cda9_row4_col1 {\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1cda9_row3_col2, #T_1cda9_row4_col2 {\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1cda9_row3_col7, #T_1cda9_row4_col7 {\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1cda9_row5_col0, #T_1cda9_row7_col3, #T_1cda9_row7_col4 {\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1cda9_row5_col1 {\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1cda9_row5_col6 {\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1cda9_row6_col0 {\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1cda9_row6_col1 {\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1cda9_row6_col2 {\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1cda9_row6_col3, #T_1cda9_row6_col4 {\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_1cda9_row6_col5 {\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1cda9_row6_col7 {\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1cda9_row7_col5 {\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_1cda9_row7_col6 {\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1cda9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1cda9_level0_col0\" class=\"col_heading level0 col0\" >boy</th>\n",
       "      <th id=\"T_1cda9_level0_col1\" class=\"col_heading level0 col1\" >kilo</th>\n",
       "      <th id=\"T_1cda9_level0_col2\" class=\"col_heading level0 col2\" >yas</th>\n",
       "      <th id=\"T_1cda9_level0_col3\" class=\"col_heading level0 col3\" >cinsiyet_e</th>\n",
       "      <th id=\"T_1cda9_level0_col4\" class=\"col_heading level0 col4\" >cinsiyet_k</th>\n",
       "      <th id=\"T_1cda9_level0_col5\" class=\"col_heading level0 col5\" >ulke_fr</th>\n",
       "      <th id=\"T_1cda9_level0_col6\" class=\"col_heading level0 col6\" >ulke_tr</th>\n",
       "      <th id=\"T_1cda9_level0_col7\" class=\"col_heading level0 col7\" >ulke_us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1cda9_level0_row0\" class=\"row_heading level0 row0\" >boy</th>\n",
       "      <td id=\"T_1cda9_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_1cda9_row0_col1\" class=\"data row0 col1\" >0.899177</td>\n",
       "      <td id=\"T_1cda9_row0_col2\" class=\"data row0 col2\" >0.508706</td>\n",
       "      <td id=\"T_1cda9_row0_col3\" class=\"data row0 col3\" >0.238393</td>\n",
       "      <td id=\"T_1cda9_row0_col4\" class=\"data row0 col4\" >0.238393</td>\n",
       "      <td id=\"T_1cda9_row0_col5\" class=\"data row0 col5\" >0.390761</td>\n",
       "      <td id=\"T_1cda9_row0_col6\" class=\"data row0 col6\" >0.432217</td>\n",
       "      <td id=\"T_1cda9_row0_col7\" class=\"data row0 col7\" >0.068487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1cda9_level0_row1\" class=\"row_heading level0 row1\" >kilo</th>\n",
       "      <td id=\"T_1cda9_row1_col0\" class=\"data row1 col0\" >0.899177</td>\n",
       "      <td id=\"T_1cda9_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_1cda9_row1_col2\" class=\"data row1 col2\" >0.423259</td>\n",
       "      <td id=\"T_1cda9_row1_col3\" class=\"data row1 col3\" >0.473871</td>\n",
       "      <td id=\"T_1cda9_row1_col4\" class=\"data row1 col4\" >0.473871</td>\n",
       "      <td id=\"T_1cda9_row1_col5\" class=\"data row1 col5\" >0.246708</td>\n",
       "      <td id=\"T_1cda9_row1_col6\" class=\"data row1 col6\" >0.302420</td>\n",
       "      <td id=\"T_1cda9_row1_col7\" class=\"data row1 col7\" >0.075849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1cda9_level0_row2\" class=\"row_heading level0 row2\" >yas</th>\n",
       "      <td id=\"T_1cda9_row2_col0\" class=\"data row2 col0\" >0.508706</td>\n",
       "      <td id=\"T_1cda9_row2_col1\" class=\"data row2 col1\" >0.423259</td>\n",
       "      <td id=\"T_1cda9_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_1cda9_row2_col3\" class=\"data row2 col3\" >0.247153</td>\n",
       "      <td id=\"T_1cda9_row2_col4\" class=\"data row2 col4\" >0.247153</td>\n",
       "      <td id=\"T_1cda9_row2_col5\" class=\"data row2 col5\" >0.209387</td>\n",
       "      <td id=\"T_1cda9_row2_col6\" class=\"data row2 col6\" >0.685811</td>\n",
       "      <td id=\"T_1cda9_row2_col7\" class=\"data row2 col7\" >0.538132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1cda9_level0_row3\" class=\"row_heading level0 row3\" >cinsiyet_e</th>\n",
       "      <td id=\"T_1cda9_row3_col0\" class=\"data row3 col0\" >0.238393</td>\n",
       "      <td id=\"T_1cda9_row3_col1\" class=\"data row3 col1\" >0.473871</td>\n",
       "      <td id=\"T_1cda9_row3_col2\" class=\"data row3 col2\" >0.247153</td>\n",
       "      <td id=\"T_1cda9_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_1cda9_row3_col4\" class=\"data row3 col4\" >1.000000</td>\n",
       "      <td id=\"T_1cda9_row3_col5\" class=\"data row3 col5\" >0.097590</td>\n",
       "      <td id=\"T_1cda9_row3_col6\" class=\"data row3 col6\" >0.277350</td>\n",
       "      <td id=\"T_1cda9_row3_col7\" class=\"data row3 col7\" >0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1cda9_level0_row4\" class=\"row_heading level0 row4\" >cinsiyet_k</th>\n",
       "      <td id=\"T_1cda9_row4_col0\" class=\"data row4 col0\" >0.238393</td>\n",
       "      <td id=\"T_1cda9_row4_col1\" class=\"data row4 col1\" >0.473871</td>\n",
       "      <td id=\"T_1cda9_row4_col2\" class=\"data row4 col2\" >0.247153</td>\n",
       "      <td id=\"T_1cda9_row4_col3\" class=\"data row4 col3\" >1.000000</td>\n",
       "      <td id=\"T_1cda9_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_1cda9_row4_col5\" class=\"data row4 col5\" >0.097590</td>\n",
       "      <td id=\"T_1cda9_row4_col6\" class=\"data row4 col6\" >0.277350</td>\n",
       "      <td id=\"T_1cda9_row4_col7\" class=\"data row4 col7\" >0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1cda9_level0_row5\" class=\"row_heading level0 row5\" >ulke_fr</th>\n",
       "      <td id=\"T_1cda9_row5_col0\" class=\"data row5 col0\" >0.390761</td>\n",
       "      <td id=\"T_1cda9_row5_col1\" class=\"data row5 col1\" >0.246708</td>\n",
       "      <td id=\"T_1cda9_row5_col2\" class=\"data row5 col2\" >0.209387</td>\n",
       "      <td id=\"T_1cda9_row5_col3\" class=\"data row5 col3\" >0.097590</td>\n",
       "      <td id=\"T_1cda9_row5_col4\" class=\"data row5 col4\" >0.097590</td>\n",
       "      <td id=\"T_1cda9_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "      <td id=\"T_1cda9_row5_col6\" class=\"data row5 col6\" >0.568399</td>\n",
       "      <td id=\"T_1cda9_row5_col7\" class=\"data row5 col7\" >0.418330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1cda9_level0_row6\" class=\"row_heading level0 row6\" >ulke_tr</th>\n",
       "      <td id=\"T_1cda9_row6_col0\" class=\"data row6 col0\" >0.432217</td>\n",
       "      <td id=\"T_1cda9_row6_col1\" class=\"data row6 col1\" >0.302420</td>\n",
       "      <td id=\"T_1cda9_row6_col2\" class=\"data row6 col2\" >0.685811</td>\n",
       "      <td id=\"T_1cda9_row6_col3\" class=\"data row6 col3\" >0.277350</td>\n",
       "      <td id=\"T_1cda9_row6_col4\" class=\"data row6 col4\" >0.277350</td>\n",
       "      <td id=\"T_1cda9_row6_col5\" class=\"data row6 col5\" >0.568399</td>\n",
       "      <td id=\"T_1cda9_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "      <td id=\"T_1cda9_row6_col7\" class=\"data row6 col7\" >0.509525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1cda9_level0_row7\" class=\"row_heading level0 row7\" >ulke_us</th>\n",
       "      <td id=\"T_1cda9_row7_col0\" class=\"data row7 col0\" >0.068487</td>\n",
       "      <td id=\"T_1cda9_row7_col1\" class=\"data row7 col1\" >0.075849</td>\n",
       "      <td id=\"T_1cda9_row7_col2\" class=\"data row7 col2\" >0.538132</td>\n",
       "      <td id=\"T_1cda9_row7_col3\" class=\"data row7 col3\" >0.408248</td>\n",
       "      <td id=\"T_1cda9_row7_col4\" class=\"data row7 col4\" >0.408248</td>\n",
       "      <td id=\"T_1cda9_row7_col5\" class=\"data row7 col5\" >0.418330</td>\n",
       "      <td id=\"T_1cda9_row7_col6\" class=\"data row7 col6\" >0.509525</td>\n",
       "      <td id=\"T_1cda9_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2defac59660>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = np.random.RandomState(0)\n",
    "new_df = pd.DataFrame(rs.rand(10,10))\n",
    "\n",
    "corr = normalized_data.loc[:,['boy', 'kilo', 'yas', 'cinsiyet_e', 'cinsiyet_k', 'ulke_fr', 'ulke_tr', 'ulke_us']].corr().abs()\n",
    "\n",
    "corr.style.background_gradient(cmap = 'coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82b0989a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['boy', 'kilo', 'yas', 'ulke_fr', 'ulke_tr'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_high_boy = corr['boy'].where(corr['boy'] >= 0.3).dropna(how='all')\n",
    "corr_high_boy.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4e16dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['boy', 'kilo', 'yas', 'cinsiyet_e', 'cinsiyet_k', 'ulke_tr'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_high_kilo = corr['kilo'].where(corr['kilo'] >= 0.3).dropna(how='all')\n",
    "corr_high_kilo.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1085b17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['boy', 'kilo', 'yas', 'ulke_tr', 'ulke_us'], dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_high_yas = corr['yas'].where(corr['yas'] >= 0.3).dropna(how='all')\n",
    "corr_high_yas.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6ef7e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# yüksek korelasyonlu featureları çıkartalım\n",
    "#corr_high_boy = corr['boy'].where(corr['boy'] >= 0.3).dropna(how='all')\n",
    "#corr_high_kilo = corr['kilo'].where(corr['kilo'] >= 0.3).dropna(how='all')\n",
    "#corr_high_yas = corr['yas'].where(corr['yas'] >= 0.3).dropna(how='all')\n",
    "#corr_high_cinsiyet_e = corr['cinsiyet_e'].where(corr['cinsiyet_e'] >= 0.3).dropna(how='all')\n",
    "#corr_high_cinsiyet_k = corr['cinsiyet_k'].where(corr['cinsiyet_k'] >= 0.3).dropna(how='all')\n",
    "#corr_high_ulke_fr = corr['ulke_fr'].where(corr['ulke_fr'] >= 0.3).dropna(how='all')\n",
    "#corr_high_ulke_tr = corr['ulke_tr'].where(corr['ulke_tr'] >= 0.3).dropna(how='all')\n",
    "#corr_high_ulke_us = corr['ulke_us'].where(corr['ulke_us'] >= 0.3).dropna(how='all')\n",
    "#\n",
    "#corr_high_boy, corr_high_kilo, corr_high_yas\n",
    "\n",
    "sns.heatmap(normalized_data.corr(), cmap=\"YlGnBu\", annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc9aba1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kilo', 'cinsiyet_k', 'ulke_tr', 'cinsiyet_k', 'ulke_us', 'ulke_tr', 'ulke_us', nan]\n"
     ]
    }
   ],
   "source": [
    "# Korelasyon matrisindeki üst üçgen kısmını maskeleyin\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Maskeleme işlemiyle sadece üst üçgen değerleri koruyun\n",
    "upper_triangle = corr.mask(mask)\n",
    "\n",
    "# Korelasyon matrisinin üst üçgen kısmında en yüksek değere sahip özellikleri bulun\n",
    "highest_corr_features = upper_triangle.idxmax().tolist()\n",
    "\n",
    "print(highest_corr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a83ccbd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cinsiyet_e</th>\n",
       "      <th>cinsiyet_k</th>\n",
       "      <th>ulke_fr</th>\n",
       "      <th>ulke_tr</th>\n",
       "      <th>ulke_us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cinsiyet_e  cinsiyet_k  ulke_fr  ulke_tr  ulke_us\n",
       "0          1.0         0.0      0.0      1.0      0.0\n",
       "1          1.0         0.0      0.0      1.0      0.0\n",
       "2          0.0         1.0      0.0      1.0      0.0\n",
       "3          0.0         1.0      0.0      1.0      0.0\n",
       "4          1.0         0.0      0.0      1.0      0.0\n",
       "5          1.0         0.0      0.0      1.0      0.0\n",
       "6          1.0         0.0      0.0      1.0      0.0\n",
       "7          1.0         0.0      0.0      1.0      0.0\n",
       "8          0.0         1.0      0.0      1.0      0.0\n",
       "9          1.0         0.0      0.0      0.0      1.0\n",
       "10         0.0         1.0      0.0      0.0      1.0\n",
       "11         0.0         1.0      0.0      0.0      1.0\n",
       "12         0.0         1.0      0.0      0.0      1.0\n",
       "13         0.0         1.0      0.0      0.0      1.0\n",
       "14         0.0         1.0      0.0      0.0      1.0\n",
       "15         1.0         0.0      1.0      0.0      0.0\n",
       "16         1.0         0.0      1.0      0.0      0.0\n",
       "17         1.0         0.0      1.0      0.0      0.0\n",
       "18         1.0         0.0      1.0      0.0      0.0\n",
       "19         0.0         1.0      1.0      0.0      0.0\n",
       "20         0.0         1.0      1.0      0.0      0.0\n",
       "21         0.0         1.0      1.0      0.0      0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1cc7a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['boy', 'kilo', 'yas', 'cinsiyet_e', 'cinsiyet_k', 'ulke_fr', 'ulke_tr','ulke_us']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abd28b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = normalized_data['kilo']\n",
    "y = normalized_data['boy']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "254d0cb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The indices for endog and exog are not aligned",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m X_train_sm \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(X_train)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Fit the regression line using 'OLS'\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOLS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mboy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_sm\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m      5\u001b[0m lr\u001b[38;5;241m.\u001b[39mparams\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:922\u001b[0m, in \u001b[0;36mOLS.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    919\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    920\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn exception will be raised in the next version.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    921\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, ValueWarning)\n\u001b[1;32m--> 922\u001b[0m \u001b[38;5;28msuper\u001b[39m(OLS, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    923\u001b[0m                           hasconst\u001b[38;5;241m=\u001b[39mhasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys:\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:748\u001b[0m, in \u001b[0;36mWLS.__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m--> 748\u001b[0m \u001b[38;5;28msuper\u001b[39m(WLS, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, missing\u001b[38;5;241m=\u001b[39mmissing,\n\u001b[0;32m    749\u001b[0m                           weights\u001b[38;5;241m=\u001b[39mweights, hasconst\u001b[38;5;241m=\u001b[39mhasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    750\u001b[0m nobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    751\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:202\u001b[0m, in \u001b[0;36mRegressionModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28msuper\u001b[39m(RegressionModel, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog: Float64Array \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_attr\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpinv_wexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwendog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\lib\\site-packages\\statsmodels\\base\\model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\lib\\site-packages\\statsmodels\\base\\model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_data(endog, exog, missing, hasconst,\n\u001b[0;32m     96\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\lib\\site-packages\\statsmodels\\base\\model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m handle_data(endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\lib\\site-packages\\statsmodels\\base\\data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[1;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m klass(endog, exog\u001b[38;5;241m=\u001b[39mexog, missing\u001b[38;5;241m=\u001b[39mmissing, hasconst\u001b[38;5;241m=\u001b[39mhasconst,\n\u001b[0;32m    676\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\lib\\site-packages\\statsmodels\\base\\data.py:89\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_constant(hasconst)\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_integrity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\notebook\\lib\\site-packages\\statsmodels\\base\\data.py:533\u001b[0m, in \u001b[0;36mPandasData._check_integrity\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;66;03m# exog can be None and we could be upcasting one or the other\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    531\u001b[0m         (\u001b[38;5;28mhasattr\u001b[39m(endog, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(exog, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_endog\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_exog\u001b[38;5;241m.\u001b[39mindex)):\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe indices for endog and exog are not aligned\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28msuper\u001b[39m(PandasData, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_check_integrity()\n",
      "\u001b[1;31mValueError\u001b[0m: The indices for endog and exog are not aligned"
     ]
    }
   ],
   "source": [
    "X_train_sm = sm.add_constant(X_train)\n",
    "\n",
    "# Fit the regression line using 'OLS'\n",
    "lr = sm.OLS(normalized_data['boy'], X_train_sm).fit()\n",
    "lr.params #kiloyu alcaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18d1208f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boy</th>\n",
       "      <th>kilo</th>\n",
       "      <th>yas</th>\n",
       "      <th>cinsiyet_e</th>\n",
       "      <th>cinsiyet_k</th>\n",
       "      <th>ulke_fr</th>\n",
       "      <th>ulke_tr</th>\n",
       "      <th>ulke_us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.544118</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         boy      kilo       yas  cinsiyet_e  cinsiyet_k  ulke_fr  ulke_tr  \\\n",
       "0   0.073529  0.000000  0.021739         1.0         0.0      0.0      1.0   \n",
       "1   0.000000  0.080000  0.043478         1.0         0.0      0.0      1.0   \n",
       "2   0.147059  0.053333  0.021739         0.0         1.0      0.0      1.0   \n",
       "3   0.117647  0.000000  0.000000         0.0         1.0      0.0      1.0   \n",
       "4   0.058824  0.106667  0.065217         1.0         0.0      0.0      1.0   \n",
       "5   0.808824  0.800000  0.456522         1.0         0.0      0.0      1.0   \n",
       "6   0.955882  0.666667  0.347826         1.0         0.0      0.0      1.0   \n",
       "7   0.735294  0.800000  0.565217         1.0         0.0      0.0      1.0   \n",
       "8   0.764706  0.400000  0.282609         0.0         1.0      0.0      1.0   \n",
       "9   0.882353  1.000000  0.521739         1.0         0.0      0.0      0.0   \n",
       "10  0.588235  0.333333  0.391304         0.0         1.0      0.0      0.0   \n",
       "11  0.441176  0.266667  0.760870         0.0         1.0      0.0      0.0   \n",
       "12  0.514706  0.373333  0.652174         0.0         1.0      0.0      0.0   \n",
       "13  0.544118  0.386667  0.695652         0.0         1.0      0.0      0.0   \n",
       "14  0.617647  0.426667  1.000000         0.0         1.0      0.0      0.0   \n",
       "15  0.720588  0.533333  0.826087         1.0         0.0      1.0      0.0   \n",
       "16  1.000000  0.800000  0.304348         1.0         0.0      1.0      0.0   \n",
       "17  0.911765  0.666667  0.391304         1.0         0.0      1.0      0.0   \n",
       "18  0.852941  0.773333  0.413043         1.0         0.0      1.0      0.0   \n",
       "19  0.500000  0.133333  0.434783         0.0         1.0      1.0      0.0   \n",
       "20  0.573529  0.480000  0.500000         0.0         1.0      1.0      0.0   \n",
       "21  0.602941  0.346667  0.717391         0.0         1.0      1.0      0.0   \n",
       "\n",
       "    ulke_us  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "5       0.0  \n",
       "6       0.0  \n",
       "7       0.0  \n",
       "8       0.0  \n",
       "9       1.0  \n",
       "10      1.0  \n",
       "11      1.0  \n",
       "12      1.0  \n",
       "13      1.0  \n",
       "14      1.0  \n",
       "15      0.0  \n",
       "16      0.0  \n",
       "17      0.0  \n",
       "18      0.0  \n",
       "19      0.0  \n",
       "20      0.0  \n",
       "21      0.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03be3f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0cb2ef6",
   "metadata": {},
   "source": [
    "## bir üstteki indent için bir alternatif yaratalım. inceleme açısından fayda görebiliriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb014d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(normalized_data, y, train_size = 0.7, test_size = 0.3, random_state = 42)\n",
    "r2 = LinearRegression()\n",
    "r2.fit(x_train, y_train)\n",
    "\n",
    "y_pred = r2.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0416d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.append( arr = np.ones(22,1).astype(float), values=normalized_data,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb71d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "62e564d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating independent and dependent variable\n",
    "X = normalized_data.iloc[:,1:].values\n",
    "y = normalized_data.iloc[:,0].values\n",
    "#splitting normalized_data into training and testing normalized_data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95f07b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb29636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automating backward elimination technique\n",
    "\n",
    "def DoBackwardElimination(the_regressor, X, y, minP2eliminate):\n",
    "    \n",
    "    assert np.shape(X)[0] == np.shape(y)[0], 'Length of X and y do not match'\n",
    "    assert minP2eliminate > 0, 'Minimum P value to eliminate cannot be zero or negative'\n",
    "    \n",
    "    original_list = list(range(0, np.shape(the_regressor.pvalues)[0]))\n",
    "    \n",
    "    max_p = 10        # Initializing with random value of maximum P value\n",
    "    i = 0\n",
    "    r2adjusted = []   # Will store R Square adjusted value for each loop\n",
    "    r2 = []           # Will store R Square value  for each loop\n",
    "    list_of_originallist = [] # Will store modified index of X at each loop\n",
    "    classifiers_list = [] # fitted classifiers at each loop\n",
    "    \n",
    "    while max_p >= minP2eliminate:\n",
    "        \n",
    "        p_values = list(the_regressor.pvalues)\n",
    "        r2adjusted.append(the_regressor.rsquared_adj)\n",
    "        r2.append(the_regressor.rsquared)\n",
    "        list_of_originallist.append(original_list)\n",
    "        \n",
    "        max_p = max(p_values)\n",
    "        max_p_idx = p_values.index(max_p)\n",
    "        \n",
    "        if max_p_idx == 0:\n",
    "            \n",
    "            temp_p = set(p_values)\n",
    "            \n",
    "            # removing the largest element from temp list\n",
    "            temp_p.remove(max(temp_p))\n",
    "            \n",
    "            max_p = max(temp_p)\n",
    "            max_p_idx = p_values.index(max_p)\n",
    "            \n",
    "            print('Index value 0 found!! Next index value is {}'.format(max_p_idx))\n",
    "            \n",
    "            if max_p < minP2eliminate:\n",
    "                \n",
    "                print('Max P value found less than 0.1 with 0 index ...Loop Ends!!')\n",
    "                \n",
    "                break\n",
    "                \n",
    "        if max_p < minP2eliminate:\n",
    "            \n",
    "            print('Max P value found less than 0.1 without 0 index...Loop Ends!!')\n",
    "            \n",
    "            break\n",
    "        \n",
    "        val_at_idx = original_list[max_p_idx]\n",
    "        \n",
    "        idx_in_org_lst = original_list.index(val_at_idx)\n",
    "        \n",
    "        original_list.remove(val_at_idx)\n",
    "        \n",
    "        print('Popped column index out of original array is {} with P-Value {}'.format(val_at_idx, np.round(np.array(p_values)[max_p_idx], decimals= 4)))\n",
    "        \n",
    "        X_new = X[:, original_list]\n",
    "        \n",
    "        the_regressor = sm.OLS(endog = y, exog = X_new).fit()\n",
    "        classifiers_list.append(the_regressor)\n",
    "        \n",
    "        print('==================================================================================================')\n",
    "        \n",
    "    return classifiers_list, r2, r2adjusted, list_of_originallist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a3ff212f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boy</th>\n",
       "      <th>kilo</th>\n",
       "      <th>yas</th>\n",
       "      <th>cinsiyet_e</th>\n",
       "      <th>cinsiyet_k</th>\n",
       "      <th>ulke_fr</th>\n",
       "      <th>ulke_tr</th>\n",
       "      <th>ulke_us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.544118</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         boy      kilo       yas  cinsiyet_e  cinsiyet_k  ulke_fr  ulke_tr  \\\n",
       "0   0.073529  0.000000  0.021739         1.0         0.0      0.0      1.0   \n",
       "1   0.000000  0.080000  0.043478         1.0         0.0      0.0      1.0   \n",
       "2   0.147059  0.053333  0.021739         0.0         1.0      0.0      1.0   \n",
       "3   0.117647  0.000000  0.000000         0.0         1.0      0.0      1.0   \n",
       "4   0.058824  0.106667  0.065217         1.0         0.0      0.0      1.0   \n",
       "5   0.808824  0.800000  0.456522         1.0         0.0      0.0      1.0   \n",
       "6   0.955882  0.666667  0.347826         1.0         0.0      0.0      1.0   \n",
       "7   0.735294  0.800000  0.565217         1.0         0.0      0.0      1.0   \n",
       "8   0.764706  0.400000  0.282609         0.0         1.0      0.0      1.0   \n",
       "9   0.882353  1.000000  0.521739         1.0         0.0      0.0      0.0   \n",
       "10  0.588235  0.333333  0.391304         0.0         1.0      0.0      0.0   \n",
       "11  0.441176  0.266667  0.760870         0.0         1.0      0.0      0.0   \n",
       "12  0.514706  0.373333  0.652174         0.0         1.0      0.0      0.0   \n",
       "13  0.544118  0.386667  0.695652         0.0         1.0      0.0      0.0   \n",
       "14  0.617647  0.426667  1.000000         0.0         1.0      0.0      0.0   \n",
       "15  0.720588  0.533333  0.826087         1.0         0.0      1.0      0.0   \n",
       "16  1.000000  0.800000  0.304348         1.0         0.0      1.0      0.0   \n",
       "17  0.911765  0.666667  0.391304         1.0         0.0      1.0      0.0   \n",
       "18  0.852941  0.773333  0.413043         1.0         0.0      1.0      0.0   \n",
       "19  0.500000  0.133333  0.434783         0.0         1.0      1.0      0.0   \n",
       "20  0.573529  0.480000  0.500000         0.0         1.0      1.0      0.0   \n",
       "21  0.602941  0.346667  0.717391         0.0         1.0      1.0      0.0   \n",
       "\n",
       "    ulke_us  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "5       0.0  \n",
       "6       0.0  \n",
       "7       0.0  \n",
       "8       0.0  \n",
       "9       1.0  \n",
       "10      1.0  \n",
       "11      1.0  \n",
       "12      1.0  \n",
       "13      1.0  \n",
       "14      1.0  \n",
       "15      0.0  \n",
       "16      0.0  \n",
       "17      0.0  \n",
       "18      0.0  \n",
       "19      0.0  \n",
       "20      0.0  \n",
       "21      0.0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "18719b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.894\n",
      "Model:                            OLS   Adj. R-squared:                  0.836\n",
      "Method:                 Least Squares   F-statistic:                     15.23\n",
      "Date:                Fri, 21 Jul 2023   Prob (F-statistic):           0.000367\n",
      "Time:                        21:49:02   Log-Likelihood:                 13.803\n",
      "No. Observations:                  15   AIC:                            -15.61\n",
      "Df Residuals:                       9   BIC:                            -11.36\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.9810      0.245      4.003      0.003       0.427       1.535\n",
      "x2             0.0484      0.189      0.257      0.803      -0.378       0.475\n",
      "x3             0.0092      0.127      0.072      0.944      -0.277       0.296\n",
      "x4             0.1445      0.062      2.322      0.045       0.004       0.285\n",
      "x5             0.1546      0.067      2.310      0.046       0.003       0.306\n",
      "x6             0.0108      0.049      0.219      0.831      -0.101       0.122\n",
      "x7            -0.0117      0.099     -0.118      0.908      -0.236       0.213\n",
      "==============================================================================\n",
      "Omnibus:                        8.152   Durbin-Watson:                   1.209\n",
      "Prob(Omnibus):                  0.017   Jarque-Bera (JB):                4.636\n",
      "Skew:                           1.201   Prob(JB):                       0.0985\n",
      "Kurtosis:                       4.285   Cond. No.                     1.34e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.07e-31. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\scipy\\stats\\_stats_py.py:1772: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=15\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data\n",
    "\n",
    "X = normalized_data.iloc[:, 1:].values         # Selecting all columns except last one that is 'boy'.\n",
    "y = normalized_data['boy'].values\n",
    "\n",
    "# # Adding constant values at start of array X\n",
    "# X = np.append(arr = np.ones((X.shape[0], 1)).astype(int), values=X, axis=1)\n",
    "\n",
    "regressor_SLR_OLS = sm.OLS(endog = y_train, exog = X_train).fit()\n",
    "\n",
    "# Looking at the summary of regressor\n",
    "print(regressor_SLR_OLS.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a4aac",
   "metadata": {},
   "source": [
    "#### x3 baya büyük geldi önce onu çıkartalım. (P testi sonucu olarak) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3248ae8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.885\n",
      "Model:                            OLS   Adj. R-squared:                  0.849\n",
      "Method:                 Least Squares   F-statistic:                     24.69\n",
      "Date:                Fri, 21 Jul 2023   Prob (F-statistic):           5.41e-07\n",
      "Time:                        21:49:02   Log-Likelihood:                 18.879\n",
      "No. Observations:                  22   AIC:                            -25.76\n",
      "Df Residuals:                      16   BIC:                            -19.21\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.0160      0.131      7.737      0.000       0.738       1.294\n",
      "x2             0.0550      0.149      0.369      0.717      -0.261       0.371\n",
      "x3             0.0158      0.069      0.228      0.822      -0.130       0.162\n",
      "x4             0.1716      0.061      2.815      0.012       0.042       0.301\n",
      "x5             0.0848      0.075      1.133      0.274      -0.074       0.243\n",
      "x6            -0.0563      0.095     -0.595      0.560      -0.257       0.145\n",
      "==============================================================================\n",
      "Omnibus:                        1.031   Durbin-Watson:                   2.759\n",
      "Prob(Omnibus):                  0.597   Jarque-Bera (JB):                0.624\n",
      "Skew:                           0.407   Prob(JB):                        0.732\n",
      "Kurtosis:                       2.863   Cond. No.                         7.38\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Remove x3 from the X array\n",
    "X = X[:, [0, 1, 2, 3, 4, 6]]  # Remove the column associated with x3 (index 5) from X\n",
    "\n",
    "# Fit the new regression model after removing x3\n",
    "regressor_SLR_OLS = sm.OLS(endog=y, exog=X).fit()\n",
    "\n",
    "# Looking at the summary of the updated regressor after removing x3\n",
    "print(regressor_SLR_OLS.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc9fdee",
   "metadata": {},
   "source": [
    "#### x3 değeri üzerinde tekrar bi işlem daha (backward elimination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4733ad10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.885\n",
      "Model:                            OLS   Adj. R-squared:                  0.849\n",
      "Method:                 Least Squares   F-statistic:                     24.69\n",
      "Date:                Fri, 21 Jul 2023   Prob (F-statistic):           5.41e-07\n",
      "Time:                        21:49:03   Log-Likelihood:                 18.879\n",
      "No. Observations:                  22   AIC:                            -25.76\n",
      "Df Residuals:                      16   BIC:                            -19.21\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0563      0.040      1.411      0.177      -0.028       0.141\n",
      "x1             1.0160      0.131      7.737      0.000       0.738       1.294\n",
      "x2             0.0550      0.149      0.369      0.717      -0.261       0.371\n",
      "x3            -0.0498      0.047     -1.060      0.305      -0.149       0.050\n",
      "x4             0.1061      0.037      2.887      0.011       0.028       0.184\n",
      "x5             0.0941      0.043      2.198      0.043       0.003       0.185\n",
      "x6             0.0093      0.043      0.214      0.833      -0.083       0.101\n",
      "x7            -0.0471      0.059     -0.795      0.438      -0.173       0.078\n",
      "==============================================================================\n",
      "Omnibus:                        1.031   Durbin-Watson:                   2.759\n",
      "Prob(Omnibus):                  0.597   Jarque-Bera (JB):                0.624\n",
      "Skew:                           0.407   Prob(JB):                        0.732\n",
      "Kurtosis:                       2.863   Cond. No.                     3.46e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.09e-32. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.884\n",
      "Model:                            OLS   Adj. R-squared:                  0.857\n",
      "Method:                 Least Squares   F-statistic:                     32.47\n",
      "Date:                Fri, 21 Jul 2023   Prob (F-statistic):           9.32e-08\n",
      "Time:                        21:49:03   Log-Likelihood:                 18.786\n",
      "No. Observations:                  22   AIC:                            -27.57\n",
      "Df Residuals:                      17   BIC:                            -22.12\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0649      0.032      2.057      0.055      -0.002       0.131\n",
      "x1             1.0373      0.115      9.029      0.000       0.795       1.280\n",
      "x2            -0.0493      0.046     -1.077      0.297      -0.146       0.047\n",
      "x3             0.1141      0.029      3.964      0.001       0.053       0.175\n",
      "x4             0.0986      0.040      2.466      0.025       0.014       0.183\n",
      "x5             0.0018      0.037      0.048      0.962      -0.077       0.081\n",
      "x6            -0.0355      0.049     -0.726      0.478      -0.139       0.068\n",
      "==============================================================================\n",
      "Omnibus:                        0.871   Durbin-Watson:                   2.719\n",
      "Prob(Omnibus):                  0.647   Jarque-Bera (JB):                0.459\n",
      "Skew:                           0.351   Prob(JB):                        0.795\n",
      "Kurtosis:                       2.910   Cond. No.                     2.52e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 7.03e-32. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data\n",
    "X = normalized_data.iloc[:, 1:].values\n",
    "y = normalized_data['boy'].values\n",
    "\n",
    "# Adding constant values at the start of array X\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the initial regression model with all predictors\n",
    "regressor_SLR_OLS = sm.OLS(endog=y, exog=X).fit()\n",
    "\n",
    "# Looking at the summary of the initial regressor\n",
    "print(regressor_SLR_OLS.summary())\n",
    "\n",
    "# Remove x3 from the X array\n",
    "X = np.delete(X, 2, axis=1)  # Remove the column associated with x3 (index 2) from X\n",
    "\n",
    "# Fit the new regression model after removing x3\n",
    "regressor_SLR_OLS = sm.OLS(endog=y, exog=X).fit()\n",
    "\n",
    "# Looking at the summary of the updated regressor after removing x3\n",
    "print(regressor_SLR_OLS.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3327c6",
   "metadata": {},
   "source": [
    "#### bu sefer de x çıkartarak backward elimination yapalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8ade7259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.885\n",
      "Model:                            OLS   Adj. R-squared:                  0.849\n",
      "Method:                 Least Squares   F-statistic:                     24.69\n",
      "Date:                Fri, 21 Jul 2023   Prob (F-statistic):           5.41e-07\n",
      "Time:                        21:49:03   Log-Likelihood:                 18.879\n",
      "No. Observations:                  22   AIC:                            -25.76\n",
      "Df Residuals:                      16   BIC:                            -19.21\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0563      0.040      1.411      0.177      -0.028       0.141\n",
      "x1             1.0160      0.131      7.737      0.000       0.738       1.294\n",
      "x2             0.0550      0.149      0.369      0.717      -0.261       0.371\n",
      "x3            -0.0498      0.047     -1.060      0.305      -0.149       0.050\n",
      "x4             0.1061      0.037      2.887      0.011       0.028       0.184\n",
      "x5             0.0941      0.043      2.198      0.043       0.003       0.185\n",
      "x6             0.0093      0.043      0.214      0.833      -0.083       0.101\n",
      "x7            -0.0471      0.059     -0.795      0.438      -0.173       0.078\n",
      "==============================================================================\n",
      "Omnibus:                        1.031   Durbin-Watson:                   2.759\n",
      "Prob(Omnibus):                  0.597   Jarque-Bera (JB):                0.624\n",
      "Skew:                           0.407   Prob(JB):                        0.732\n",
      "Kurtosis:                       2.863   Cond. No.                     3.46e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.09e-32. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.884\n",
      "Model:                            OLS   Adj. R-squared:                  0.857\n",
      "Method:                 Least Squares   F-statistic:                     32.47\n",
      "Date:                Fri, 21 Jul 2023   Prob (F-statistic):           9.32e-08\n",
      "Time:                        21:49:03   Log-Likelihood:                 18.786\n",
      "No. Observations:                  22   AIC:                            -27.57\n",
      "Df Residuals:                      17   BIC:                            -22.12\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1306      0.049      2.673      0.016       0.028       0.234\n",
      "x1             1.0373      0.115      9.029      0.000       0.795       1.280\n",
      "x2            -0.0164      0.051     -0.324      0.750      -0.123       0.090\n",
      "x3             0.1470      0.032      4.535      0.000       0.079       0.215\n",
      "x4            -0.0968      0.066     -1.473      0.159      -0.235       0.042\n",
      "x5            -0.1340      0.070     -1.928      0.071      -0.281       0.013\n",
      "==============================================================================\n",
      "Omnibus:                        0.871   Durbin-Watson:                   2.719\n",
      "Prob(Omnibus):                  0.647   Jarque-Bera (JB):                0.459\n",
      "Skew:                           0.351   Prob(JB):                        0.795\n",
      "Kurtosis:                       2.910   Cond. No.                     1.88e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.22e-31. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "X = normalized_data.iloc[:, 1:].values\n",
    "y = normalized_data['boy'].values\n",
    "\n",
    "# Adding constant values at the start of array X\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the initial regression model with all predictors\n",
    "regressor_SLR_OLS = sm.OLS(endog=y, exog=X).fit()\n",
    "\n",
    "# Looking at the summary of the initial regressor\n",
    "print(regressor_SLR_OLS.summary())\n",
    "\n",
    "# Remove x3 and x5 from the X array\n",
    "X = np.delete(X, [2, 5], axis=1)  # Remove the columns associated with x3 (index 2) and x5 (index 4) from X\n",
    "\n",
    "# Fit the new regression model after removing x3 and x5\n",
    "regressor_SLR_OLS = sm.OLS(endog=y, exog=X).fit()\n",
    "\n",
    "# Looking at the summary of the updated regressor after removing x3 and x5\n",
    "print(regressor_SLR_OLS.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae94c1",
   "metadata": {},
   "source": [
    "#### bu sefer de x2 çıkartıp backward elimination işlemine devam edelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f3dbddf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.329\n",
      "Model:                            OLS   Adj. R-squared:                  0.218\n",
      "Method:                 Least Squares   F-statistic:                     2.947\n",
      "Date:                Fri, 21 Jul 2023   Prob (F-statistic):             0.0607\n",
      "Time:                        21:49:04   Log-Likelihood:               -0.54112\n",
      "No. Observations:                  22   AIC:                             9.082\n",
      "Df Residuals:                      18   BIC:                             13.45\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.4810      0.069      6.935      0.000       0.335       0.627\n",
      "x1             0.3517      0.070      5.003      0.000       0.204       0.499\n",
      "x2             0.1293      0.076      1.709      0.105      -0.030       0.288\n",
      "x3            -0.3517      0.139     -2.536      0.021      -0.643      -0.060\n",
      "x4            -0.0494      0.161     -0.306      0.763      -0.388       0.289\n",
      "==============================================================================\n",
      "Omnibus:                        0.344   Durbin-Watson:                   0.934\n",
      "Prob(Omnibus):                  0.842   Jarque-Bera (JB):                0.034\n",
      "Skew:                           0.095   Prob(JB):                        0.983\n",
      "Kurtosis:                       2.969   Cond. No.                     2.18e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 8.12e-32. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "X = np.delete(X, 1, axis=1)  # X içinden x2 (indeks 1) değişkenini çıkarın\n",
    "regressor_SLR_OLS = sm.OLS(endog=y, exog=X).fit()\n",
    "\n",
    "print(regressor_SLR_OLS.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d940a29c",
   "metadata": {},
   "source": [
    "#### bu sefer de x4 çıkartıp backward elimination işlemine devam edelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b292fd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.855\n",
      "Model:                            OLS   Adj. R-squared:                  0.830\n",
      "Method:                 Least Squares   F-statistic:                     35.28\n",
      "Date:                Fri, 21 Jul 2023   Prob (F-statistic):           9.51e-08\n",
      "Time:                        21:49:05   Log-Likelihood:                 16.279\n",
      "No. Observations:                  22   AIC:                            -24.56\n",
      "Df Residuals:                      18   BIC:                            -20.19\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1726      0.064      2.718      0.014       0.039       0.306\n",
      "x1             1.0320      0.138      7.504      0.000       0.743       1.321\n",
      "x2             0.0385      0.132      0.293      0.773      -0.238       0.315\n",
      "x3            -0.1343      0.075     -1.799      0.089      -0.291       0.023\n",
      "==============================================================================\n",
      "Omnibus:                        1.601   Durbin-Watson:                   2.580\n",
      "Prob(Omnibus):                  0.449   Jarque-Bera (JB):                1.137\n",
      "Skew:                           0.297   Prob(JB):                        0.566\n",
      "Kurtosis:                       2.058   Cond. No.                         8.70\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Verileri işleme\n",
    "X = normalized_data.iloc[:, 1:4].values  # İlk üç değişkeni (x1, x2, x3) alın\n",
    "y = normalized_data['boy'].values\n",
    "\n",
    "# X'in başına sabit değerleri ekleyin\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Tüm öngörücülerle başlayarak ilk regresyon modelini oluşturun\n",
    "regressor_SLR_OLS = sm.OLS(endog=y, exog=X).fit()\n",
    "\n",
    "# İlk regresyon modelinin özetine bakın\n",
    "print(regressor_SLR_OLS.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac160e16",
   "metadata": {},
   "source": [
    "### x2 çıkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dd887af5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.854\n",
      "Model:                            OLS   Adj. R-squared:                  0.839\n",
      "Method:                 Least Squares   F-statistic:                     55.55\n",
      "Date:                Fri, 21 Jul 2023   Prob (F-statistic):           1.16e-08\n",
      "Time:                        21:49:05   Log-Likelihood:                 16.226\n",
      "No. Observations:                  22   AIC:                            -26.45\n",
      "Df Residuals:                      19   BIC:                            -23.18\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1843      0.048      3.825      0.001       0.083       0.285\n",
      "x1             1.0576      0.104     10.183      0.000       0.840       1.275\n",
      "x2            -0.1466      0.060     -2.431      0.025      -0.273      -0.020\n",
      "==============================================================================\n",
      "Omnibus:                        1.607   Durbin-Watson:                   2.537\n",
      "Prob(Omnibus):                  0.448   Jarque-Bera (JB):                1.076\n",
      "Skew:                           0.239   Prob(JB):                        0.584\n",
      "Kurtosis:                       2.028   Cond. No.                         5.22\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X = np.delete(X, 2, axis=1) \n",
    "regressor_SLR_OLS = sm.OLS(endog=y, exog=X).fit()\n",
    "\n",
    "print(regressor_SLR_OLS.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9945f0e3",
   "metadata": {},
   "source": [
    "## makul bir tablo yeterli çaba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5fdd9021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        kilo       yas  cinsiyet_e  cinsiyet_k  ulke_fr  ulke_tr  ulke_us\n",
       " 11  0.266667  0.760870         0.0         1.0      0.0      0.0      1.0\n",
       " 3   0.000000  0.000000         0.0         1.0      0.0      1.0      0.0\n",
       " 4   0.106667  0.065217         1.0         0.0      0.0      1.0      0.0\n",
       " 17  0.666667  0.391304         1.0         0.0      1.0      0.0      0.0\n",
       " 12  0.373333  0.652174         0.0         1.0      0.0      0.0      1.0\n",
       " 18  0.773333  0.413043         1.0         0.0      1.0      0.0      0.0\n",
       " 16  0.800000  0.304348         1.0         0.0      1.0      0.0      0.0\n",
       " 2   0.053333  0.021739         0.0         1.0      0.0      1.0      0.0\n",
       " 9   1.000000  0.521739         1.0         0.0      0.0      0.0      1.0\n",
       " 21  0.346667  0.717391         0.0         1.0      1.0      0.0      0.0\n",
       " 7   0.800000  0.565217         1.0         0.0      0.0      1.0      0.0\n",
       " 10  0.333333  0.391304         0.0         1.0      0.0      0.0      1.0\n",
       " 14  0.426667  1.000000         0.0         1.0      0.0      0.0      1.0\n",
       " 19  0.133333  0.434783         0.0         1.0      1.0      0.0      0.0\n",
       " 6   0.666667  0.347826         1.0         0.0      0.0      1.0      0.0,\n",
       "         kilo       yas  cinsiyet_e  cinsiyet_k  ulke_fr  ulke_tr  ulke_us\n",
       " 0   0.000000  0.021739         1.0         0.0      0.0      1.0      0.0\n",
       " 13  0.386667  0.695652         0.0         1.0      0.0      0.0      1.0\n",
       " 8   0.400000  0.282609         0.0         1.0      0.0      1.0      0.0\n",
       " 1   0.080000  0.043478         1.0         0.0      0.0      1.0      0.0\n",
       " 15  0.533333  0.826087         1.0         0.0      1.0      0.0      0.0\n",
       " 5   0.800000  0.456522         1.0         0.0      0.0      1.0      0.0\n",
       " 20  0.480000  0.500000         0.0         1.0      1.0      0.0      0.0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6165a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = normalized_data[[\"kilo\",\"yas\",\"cinsiyet_e\",\"cinsiyet_k\",\"ulke_fr\",\"ulke_tr\",\"ulke_us\"]]\n",
    "y = normalized_data[[\"boy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "829a6337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #model \n",
    "r2 = LinearRegression()\n",
    "r2.fit(x_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0b7bf4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02100957, 0.54580673, 0.56140155, 0.10054369, 0.727041  ,\n",
       "       0.82688298, 0.79427106])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = r2.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6c44abfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  0.12807436639105985\n",
      "Coefficients:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('kilo', 0.981011465701549),\n",
       " ('yas', 0.04844776342557715),\n",
       " ('cinsiyet_e', -0.06767442584316835),\n",
       " ('cinsiyet_k', 0.06767442584316835),\n",
       " ('ulke_fr', 0.10341287843428926),\n",
       " ('ulke_tr', -0.040443587611857096),\n",
       " ('ulke_us', -0.0629692908224322)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Intercept and Coefficient\n",
    "print(\"Intercept: \", r2.intercept_)\n",
    "print(\"Coefficients:\")\n",
    "list(zip(x, r2.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b35decb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for test set: [0.02100957 0.54580673 0.56140155 0.10054369 0.727041   0.82688298\n",
      " 0.79427106]\n"
     ]
    }
   ],
   "source": [
    "y_pred_r2= r2.predict(x_test)  \n",
    "x_pred_r2= r2.predict(x_train) \n",
    "\n",
    "print(\"Prediction for test set: {}\".format(y_pred_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "198c1816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual value</th>\n",
       "      <th>Predicted value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.021010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.544118</td>\n",
       "      <td>0.545807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.561402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.727041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual value  Predicted value\n",
       "0      0.073529         0.021010\n",
       "1      0.544118         0.545807\n",
       "2      0.764706         0.561402\n",
       "3      0.000000         0.100544\n",
       "4      0.720588         0.727041"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Actual value and the predicted value\n",
    "r2_diff = pd.DataFrame({'Actual value': y_test, 'Predicted value': y_pred_r2})\n",
    "r2_diff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fed182",
   "metadata": {},
   "source": [
    "###  mesela bir boy tahmini yapalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1e2c0b7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boy</th>\n",
       "      <th>kilo</th>\n",
       "      <th>yas</th>\n",
       "      <th>cinsiyet_e</th>\n",
       "      <th>cinsiyet_k</th>\n",
       "      <th>ulke_fr</th>\n",
       "      <th>ulke_tr</th>\n",
       "      <th>ulke_us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.544118</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         boy      kilo       yas  cinsiyet_e  cinsiyet_k  ulke_fr  ulke_tr  \\\n",
       "0   0.073529  0.000000  0.021739         1.0         0.0      0.0      1.0   \n",
       "1   0.000000  0.080000  0.043478         1.0         0.0      0.0      1.0   \n",
       "2   0.147059  0.053333  0.021739         0.0         1.0      0.0      1.0   \n",
       "3   0.117647  0.000000  0.000000         0.0         1.0      0.0      1.0   \n",
       "4   0.058824  0.106667  0.065217         1.0         0.0      0.0      1.0   \n",
       "5   0.808824  0.800000  0.456522         1.0         0.0      0.0      1.0   \n",
       "6   0.955882  0.666667  0.347826         1.0         0.0      0.0      1.0   \n",
       "7   0.735294  0.800000  0.565217         1.0         0.0      0.0      1.0   \n",
       "8   0.764706  0.400000  0.282609         0.0         1.0      0.0      1.0   \n",
       "9   0.882353  1.000000  0.521739         1.0         0.0      0.0      0.0   \n",
       "10  0.588235  0.333333  0.391304         0.0         1.0      0.0      0.0   \n",
       "11  0.441176  0.266667  0.760870         0.0         1.0      0.0      0.0   \n",
       "12  0.514706  0.373333  0.652174         0.0         1.0      0.0      0.0   \n",
       "13  0.544118  0.386667  0.695652         0.0         1.0      0.0      0.0   \n",
       "14  0.617647  0.426667  1.000000         0.0         1.0      0.0      0.0   \n",
       "15  0.720588  0.533333  0.826087         1.0         0.0      1.0      0.0   \n",
       "16  1.000000  0.800000  0.304348         1.0         0.0      1.0      0.0   \n",
       "17  0.911765  0.666667  0.391304         1.0         0.0      1.0      0.0   \n",
       "18  0.852941  0.773333  0.413043         1.0         0.0      1.0      0.0   \n",
       "19  0.500000  0.133333  0.434783         0.0         1.0      1.0      0.0   \n",
       "20  0.573529  0.480000  0.500000         0.0         1.0      1.0      0.0   \n",
       "21  0.602941  0.346667  0.717391         0.0         1.0      1.0      0.0   \n",
       "\n",
       "    ulke_us  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "5       0.0  \n",
       "6       0.0  \n",
       "7       0.0  \n",
       "8       0.0  \n",
       "9       1.0  \n",
       "10      1.0  \n",
       "11      1.0  \n",
       "12      1.0  \n",
       "13      1.0  \n",
       "14      1.0  \n",
       "15      0.0  \n",
       "16      0.0  \n",
       "17      0.0  \n",
       "18      0.0  \n",
       "19      0.0  \n",
       "20      0.0  \n",
       "21      0.0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "98a0eefd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.8184573])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.predict([[0.8, 0.282609,1.0, 0.0, 0.0, 1.0,0.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01bed2e",
   "metadata": {},
   "source": [
    "#### mesela bu sallama stilinde boy için 0.818457 değerini verdi. tabi bunu unnormalized etmek gerek."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92ff08e",
   "metadata": {},
   "source": [
    "## MAE, MSE, MAPE  ve RMSE için error hesabı "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "667ccf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "    mape = 0\n",
    "    for i in range(n):\n",
    "        if y_true[i] != 0:\n",
    "            mape += np.abs((y_true[i] - y_pred[i]) / y_true[i])\n",
    "    mape = 100 / n * mape\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "444e5cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08618725925975435\n",
      "Mean Square Error: 0.014756789828437243\n",
      "Root Mean Square Error: 0.12147752808004139\n",
      "Mean Absolute Percentage Error: % 19.991420770448517\n"
     ]
    }
   ],
   "source": [
    "meanAbErr = metrics.mean_absolute_error(y_test, y_pred_r2)\n",
    "meanSqErr = metrics.mean_squared_error(y_test, y_pred_r2)\n",
    "rootMeanSqErr = np.sqrt(metrics.mean_squared_error(y_test, y_pred_r2))\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred_r2)\n",
    "\n",
    "print('Mean Absolute Error:', meanAbErr)\n",
    "print('Mean Square Error:', meanSqErr)\n",
    "print('Root Mean Square Error:', rootMeanSqErr)\n",
    "print('Mean Absolute Percentage Error: %', mape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d989a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "[('kilo', 0.981011465701549),\n",
    " ('yas', 0.04844776342557715),\n",
    " ('cinsiyet_e', -0.06767442584316835),\n",
    " ('cinsiyet_k', 0.06767442584316835),\n",
    " ('ulke_fr', 0.10341287843428926),\n",
    " ('ulke_tr', -0.040443587611857096),\n",
    " ('ulke_us', -0.0629692908224322)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523682a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "  OLS Regression Results                            \n",
    "==============================================================================\n",
    "Dep. Variable:                      y   R-squared:                       0.854\n",
    "Model:                            OLS   Adj. R-squared:                  0.839\n",
    "Method:                 Least Squares   F-statistic:                     55.55\n",
    "Date:                Fri, 21 Jul 2023   Prob (F-statistic):           1.16e-08\n",
    "Time:                        21:49:05   Log-Likelihood:                 16.226\n",
    "No. Observations:                  22   AIC:                            -26.45\n",
    "Df Residuals:                      19   BIC:                            -23.18\n",
    "Df Model:                           2                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "==============================================================================\n",
    "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const          0.1843      0.048      3.825      0.001       0.083       0.285\n",
    "x1             1.0576      0.104     10.183      0.000       0.840       1.275\n",
    "x2            -0.1466      0.060     -2.431      0.025      -0.273      -0.020\n",
    "==============================================================================\n",
    "Omnibus:                        1.607   Durbin-Watson:                   2.537\n",
    "Prob(Omnibus):                  0.448   Jarque-Bera (JB):                1.076\n",
    "Skew:                           0.239   Prob(JB):                        0.584\n",
    "Kurtosis:                       2.028   Cond. No.                         5.22\n",
    "==============================================================================\n",
    "\n",
    "# bu tablo backward elimination son hali idi. ona göre bir tahmin yaptıralım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b68768c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.38666667, 0.4       , 0.08      , 0.53333333,\n",
       "       0.8       , 0.48      ])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747fc641",
   "metadata": {},
   "source": [
    "### elimden geldiğince multiple linear regresyon işte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3d84b27e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.scatter(x_combined, y_test)\n",
    "plt.plot(x_combined, 0.1843 + 1.0576 *x_combined, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e73c15f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceef9686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c112dafc",
   "metadata": {},
   "source": [
    "0.199968 + 0.8785 * kilo param gibi bişey olcak galiba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e47159f",
   "metadata": {},
   "source": [
    "y_train_pred = lr.predict(X_train_sm)\n",
    "res = (y_train - y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8bfde4",
   "metadata": {},
   "source": [
    "fig = plt.figure()\n",
    "sns.distplot(res, bins = 15)\n",
    "fig.suptitle('Error Terms', fontsize = 15)                  # Plot heading \n",
    "plt.xlabel('y_train - y_train_pred', fontsize = 15)         # X-label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf06c31b",
   "metadata": {},
   "source": [
    "# Add a constant to X_test\n",
    "X_test_sm = sm.add_constant(X_test)\n",
    "\n",
    "# Predict the y values corresponding to X_test_sm\n",
    "y_pred = lr.predict(X_test_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b4d5ca",
   "metadata": {},
   "source": [
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee830052",
   "metadata": {},
   "source": [
    "#Returns the mean squared error; we'll take a square root\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e81218f",
   "metadata": {},
   "source": [
    "r_squared = r2_score(y_test, y_pred)\n",
    "r_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b017d2e3",
   "metadata": {},
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d6597",
   "metadata": {},
   "source": [
    "plt.scatter(X_test, y_test)\n",
    "plt.plot(X_test, 0.199968 + 0.8785 * X_test, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf52dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244f7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "238ee17e",
   "metadata": {},
   "source": [
    "## aynı işlemleri normalizasyon değil de standardizasyon yapılmış biçimde tekrardan ayarlayalım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ad48caf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ulke', 'cinsiyet']\n",
      "['boy', 'kilo', 'yas']\n"
     ]
    }
   ],
   "source": [
    "# define the categorical columns to exclude from normalization\n",
    "categorical_columns = data.select_dtypes(include = 'object').columns.to_list()\n",
    "print(categorical_columns)\n",
    "\n",
    "categorical = categorical_columns\n",
    "\n",
    "# define the columns to include in normalization\n",
    "columns_to_standardize = [col for col in data.columns if col not in categorical]\n",
    "print(columns_to_standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d80d5ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_7784\\3958081243.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_continuous[column_name] = scaler.transform(df_continuous[[column_name]].values.reshape(-1, 1))\n",
      "C:\\Users\\Asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_7784\\3958081243.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_continuous[column_name] = scaler.transform(df_continuous[[column_name]].values.reshape(-1, 1))\n",
      "C:\\Users\\Asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_7784\\3958081243.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_continuous[column_name] = scaler.transform(df_continuous[[column_name]].values.reshape(-1, 1))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_continuous = data[columns_to_standardize]\n",
    "standardize_columns_names = list(df_continuous.columns)\n",
    "all_scalers = {}\n",
    "\n",
    "for column_name in standardize_columns_names:\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df_continuous[[column_name]])\n",
    "    all_scalers[column_name] = scaler\n",
    "    \n",
    "for column_name, scaler in all_scalers.items():\n",
    "    df_continuous[column_name] = scaler.transform(df_continuous[[column_name]].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4d5735a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ulke</th>\n",
       "      <th>boy</th>\n",
       "      <th>kilo</th>\n",
       "      <th>yas</th>\n",
       "      <th>cinsiyet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr</td>\n",
       "      <td>-1.620187</td>\n",
       "      <td>-1.475889</td>\n",
       "      <td>-1.472173</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tr</td>\n",
       "      <td>-1.862994</td>\n",
       "      <td>-1.200334</td>\n",
       "      <td>-1.393371</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tr</td>\n",
       "      <td>-1.377379</td>\n",
       "      <td>-1.292185</td>\n",
       "      <td>-1.472173</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tr</td>\n",
       "      <td>-1.474502</td>\n",
       "      <td>-1.475889</td>\n",
       "      <td>-1.550975</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tr</td>\n",
       "      <td>-1.668748</td>\n",
       "      <td>-1.108482</td>\n",
       "      <td>-1.314568</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tr</td>\n",
       "      <td>0.807886</td>\n",
       "      <td>1.279660</td>\n",
       "      <td>0.103876</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tr</td>\n",
       "      <td>1.293501</td>\n",
       "      <td>0.820402</td>\n",
       "      <td>-0.290136</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tr</td>\n",
       "      <td>0.565079</td>\n",
       "      <td>1.279660</td>\n",
       "      <td>0.497888</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tr</td>\n",
       "      <td>0.662202</td>\n",
       "      <td>-0.098114</td>\n",
       "      <td>-0.526544</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>us</td>\n",
       "      <td>1.050693</td>\n",
       "      <td>1.968547</td>\n",
       "      <td>0.340283</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>us</td>\n",
       "      <td>0.079464</td>\n",
       "      <td>-0.327743</td>\n",
       "      <td>-0.132531</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>us</td>\n",
       "      <td>-0.406150</td>\n",
       "      <td>-0.557372</td>\n",
       "      <td>1.207110</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>us</td>\n",
       "      <td>-0.163343</td>\n",
       "      <td>-0.189966</td>\n",
       "      <td>0.813098</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>us</td>\n",
       "      <td>-0.066220</td>\n",
       "      <td>-0.144040</td>\n",
       "      <td>0.970703</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>us</td>\n",
       "      <td>0.176587</td>\n",
       "      <td>-0.006263</td>\n",
       "      <td>2.073937</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fr</td>\n",
       "      <td>0.516517</td>\n",
       "      <td>0.361144</td>\n",
       "      <td>1.443518</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>fr</td>\n",
       "      <td>1.439185</td>\n",
       "      <td>1.279660</td>\n",
       "      <td>-0.447741</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fr</td>\n",
       "      <td>1.147816</td>\n",
       "      <td>0.820402</td>\n",
       "      <td>-0.132531</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fr</td>\n",
       "      <td>0.953570</td>\n",
       "      <td>1.187809</td>\n",
       "      <td>-0.053729</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fr</td>\n",
       "      <td>-0.211905</td>\n",
       "      <td>-1.016631</td>\n",
       "      <td>0.025074</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>fr</td>\n",
       "      <td>0.030903</td>\n",
       "      <td>0.177441</td>\n",
       "      <td>0.261481</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fr</td>\n",
       "      <td>0.128026</td>\n",
       "      <td>-0.281818</td>\n",
       "      <td>1.049505</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ulke       boy      kilo       yas cinsiyet\n",
       "0    tr -1.620187 -1.475889 -1.472173        e\n",
       "1    tr -1.862994 -1.200334 -1.393371        e\n",
       "2    tr -1.377379 -1.292185 -1.472173        k\n",
       "3    tr -1.474502 -1.475889 -1.550975        k\n",
       "4    tr -1.668748 -1.108482 -1.314568        e\n",
       "5    tr  0.807886  1.279660  0.103876        e\n",
       "6    tr  1.293501  0.820402 -0.290136        e\n",
       "7    tr  0.565079  1.279660  0.497888        e\n",
       "8    tr  0.662202 -0.098114 -0.526544        k\n",
       "9    us  1.050693  1.968547  0.340283        e\n",
       "10   us  0.079464 -0.327743 -0.132531        k\n",
       "11   us -0.406150 -0.557372  1.207110        k\n",
       "12   us -0.163343 -0.189966  0.813098        k\n",
       "13   us -0.066220 -0.144040  0.970703        k\n",
       "14   us  0.176587 -0.006263  2.073937        k\n",
       "15   fr  0.516517  0.361144  1.443518        e\n",
       "16   fr  1.439185  1.279660 -0.447741        e\n",
       "17   fr  1.147816  0.820402 -0.132531        e\n",
       "18   fr  0.953570  1.187809 -0.053729        e\n",
       "19   fr -0.211905 -1.016631  0.025074        k\n",
       "20   fr  0.030903  0.177441  0.261481        k\n",
       "21   fr  0.128026 -0.281818  1.049505        k"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_data = pd.concat([df_continuous,data[categorical]], axis= 1)\n",
    "standardized_data = standardized_data.reindex(data.columns, axis = 1)\n",
    "standardized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "083d3a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cinsiyet_e</th>\n",
       "      <th>cinsiyet_k</th>\n",
       "      <th>ulke_fr</th>\n",
       "      <th>ulke_tr</th>\n",
       "      <th>ulke_us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cinsiyet_e  cinsiyet_k  ulke_fr  ulke_tr  ulke_us\n",
       "0         1.0         0.0      0.0      1.0      0.0\n",
       "1         1.0         0.0      0.0      1.0      0.0\n",
       "2         0.0         1.0      0.0      1.0      0.0\n",
       "3         0.0         1.0      0.0      1.0      0.0\n",
       "4         1.0         0.0      0.0      1.0      0.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_encode = ['cinsiyet', 'ulke']\n",
    "\n",
    "# one-hot encode the selected columns and append them to your original dataframe\n",
    "encoded_cols = pd.get_dummies(data[cols_to_encode], dtype = np.float32)\n",
    "df = pd.concat([data[categorical], encoded_cols],axis=1)\n",
    "\n",
    "# drop the original columns that were one-hot encoded\n",
    "df.drop(cols_to_encode, axis=1,inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3138ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# float veri oluşturan columnları hazırlayalım\n",
    "float_columns = standardized_data.select_dtypes(include=['float']).columns\n",
    "float_data = standardized_data[float_columns]\n",
    "\n",
    "standardized_data = pd.concat([float_data, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fb74758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\seaborn\\axisgrid.py:118: UserWarning: The figure layout has changed to tight\n",
      "  self._figure.tight_layout(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# yaşa göre boy ve kilo dağılımı\n",
    "sns.pairplot(data, x_vars=['boy', 'kilo'], y_vars='yas', height=4, aspect=1, kind='scatter')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f9f62f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_19463_row0_col0, #T_19463_row1_col1, #T_19463_row2_col2, #T_19463_row3_col3, #T_19463_row3_col4, #T_19463_row4_col3, #T_19463_row4_col4, #T_19463_row5_col5, #T_19463_row6_col6, #T_19463_row7_col7 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19463_row0_col1, #T_19463_row1_col0 {\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19463_row0_col2, #T_19463_row2_col1, #T_19463_row5_col7 {\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19463_row0_col3, #T_19463_row0_col4 {\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19463_row0_col5 {\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19463_row0_col6 {\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19463_row0_col7, #T_19463_row3_col5, #T_19463_row3_col6, #T_19463_row4_col5, #T_19463_row4_col6, #T_19463_row5_col2, #T_19463_row5_col3, #T_19463_row5_col4, #T_19463_row7_col0, #T_19463_row7_col1 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19463_row1_col2 {\n",
       "  background-color: #94b6ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19463_row1_col3, #T_19463_row1_col4, #T_19463_row7_col2 {\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19463_row1_col5, #T_19463_row2_col3, #T_19463_row2_col4 {\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19463_row1_col6 {\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19463_row1_col7 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19463_row2_col0 {\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19463_row2_col5 {\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19463_row2_col6 {\n",
       "  background-color: #ecd3c5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19463_row2_col7 {\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19463_row3_col0, #T_19463_row4_col0 {\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19463_row3_col1, #T_19463_row4_col1 {\n",
       "  background-color: #cad8ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19463_row3_col2, #T_19463_row4_col2 {\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19463_row3_col7, #T_19463_row4_col7 {\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19463_row5_col0, #T_19463_row7_col3, #T_19463_row7_col4 {\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19463_row5_col1 {\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19463_row5_col6 {\n",
       "  background-color: #c1d4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19463_row6_col0 {\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19463_row6_col1 {\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19463_row6_col2 {\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19463_row6_col3, #T_19463_row6_col4 {\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_19463_row6_col5 {\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19463_row6_col7 {\n",
       "  background-color: #d6dce4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19463_row7_col5 {\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_19463_row7_col6 {\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_19463\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_19463_level0_col0\" class=\"col_heading level0 col0\" >boy</th>\n",
       "      <th id=\"T_19463_level0_col1\" class=\"col_heading level0 col1\" >kilo</th>\n",
       "      <th id=\"T_19463_level0_col2\" class=\"col_heading level0 col2\" >yas</th>\n",
       "      <th id=\"T_19463_level0_col3\" class=\"col_heading level0 col3\" >cinsiyet_e</th>\n",
       "      <th id=\"T_19463_level0_col4\" class=\"col_heading level0 col4\" >cinsiyet_k</th>\n",
       "      <th id=\"T_19463_level0_col5\" class=\"col_heading level0 col5\" >ulke_fr</th>\n",
       "      <th id=\"T_19463_level0_col6\" class=\"col_heading level0 col6\" >ulke_tr</th>\n",
       "      <th id=\"T_19463_level0_col7\" class=\"col_heading level0 col7\" >ulke_us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_19463_level0_row0\" class=\"row_heading level0 row0\" >boy</th>\n",
       "      <td id=\"T_19463_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_19463_row0_col1\" class=\"data row0 col1\" >0.899177</td>\n",
       "      <td id=\"T_19463_row0_col2\" class=\"data row0 col2\" >0.508706</td>\n",
       "      <td id=\"T_19463_row0_col3\" class=\"data row0 col3\" >0.238393</td>\n",
       "      <td id=\"T_19463_row0_col4\" class=\"data row0 col4\" >0.238393</td>\n",
       "      <td id=\"T_19463_row0_col5\" class=\"data row0 col5\" >0.390761</td>\n",
       "      <td id=\"T_19463_row0_col6\" class=\"data row0 col6\" >0.432217</td>\n",
       "      <td id=\"T_19463_row0_col7\" class=\"data row0 col7\" >0.068487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19463_level0_row1\" class=\"row_heading level0 row1\" >kilo</th>\n",
       "      <td id=\"T_19463_row1_col0\" class=\"data row1 col0\" >0.899177</td>\n",
       "      <td id=\"T_19463_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_19463_row1_col2\" class=\"data row1 col2\" >0.423259</td>\n",
       "      <td id=\"T_19463_row1_col3\" class=\"data row1 col3\" >0.473871</td>\n",
       "      <td id=\"T_19463_row1_col4\" class=\"data row1 col4\" >0.473871</td>\n",
       "      <td id=\"T_19463_row1_col5\" class=\"data row1 col5\" >0.246708</td>\n",
       "      <td id=\"T_19463_row1_col6\" class=\"data row1 col6\" >0.302420</td>\n",
       "      <td id=\"T_19463_row1_col7\" class=\"data row1 col7\" >0.075849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19463_level0_row2\" class=\"row_heading level0 row2\" >yas</th>\n",
       "      <td id=\"T_19463_row2_col0\" class=\"data row2 col0\" >0.508706</td>\n",
       "      <td id=\"T_19463_row2_col1\" class=\"data row2 col1\" >0.423259</td>\n",
       "      <td id=\"T_19463_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "      <td id=\"T_19463_row2_col3\" class=\"data row2 col3\" >0.247153</td>\n",
       "      <td id=\"T_19463_row2_col4\" class=\"data row2 col4\" >0.247153</td>\n",
       "      <td id=\"T_19463_row2_col5\" class=\"data row2 col5\" >0.209387</td>\n",
       "      <td id=\"T_19463_row2_col6\" class=\"data row2 col6\" >0.685811</td>\n",
       "      <td id=\"T_19463_row2_col7\" class=\"data row2 col7\" >0.538132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19463_level0_row3\" class=\"row_heading level0 row3\" >cinsiyet_e</th>\n",
       "      <td id=\"T_19463_row3_col0\" class=\"data row3 col0\" >0.238393</td>\n",
       "      <td id=\"T_19463_row3_col1\" class=\"data row3 col1\" >0.473871</td>\n",
       "      <td id=\"T_19463_row3_col2\" class=\"data row3 col2\" >0.247153</td>\n",
       "      <td id=\"T_19463_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "      <td id=\"T_19463_row3_col4\" class=\"data row3 col4\" >1.000000</td>\n",
       "      <td id=\"T_19463_row3_col5\" class=\"data row3 col5\" >0.097590</td>\n",
       "      <td id=\"T_19463_row3_col6\" class=\"data row3 col6\" >0.277350</td>\n",
       "      <td id=\"T_19463_row3_col7\" class=\"data row3 col7\" >0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19463_level0_row4\" class=\"row_heading level0 row4\" >cinsiyet_k</th>\n",
       "      <td id=\"T_19463_row4_col0\" class=\"data row4 col0\" >0.238393</td>\n",
       "      <td id=\"T_19463_row4_col1\" class=\"data row4 col1\" >0.473871</td>\n",
       "      <td id=\"T_19463_row4_col2\" class=\"data row4 col2\" >0.247153</td>\n",
       "      <td id=\"T_19463_row4_col3\" class=\"data row4 col3\" >1.000000</td>\n",
       "      <td id=\"T_19463_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "      <td id=\"T_19463_row4_col5\" class=\"data row4 col5\" >0.097590</td>\n",
       "      <td id=\"T_19463_row4_col6\" class=\"data row4 col6\" >0.277350</td>\n",
       "      <td id=\"T_19463_row4_col7\" class=\"data row4 col7\" >0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19463_level0_row5\" class=\"row_heading level0 row5\" >ulke_fr</th>\n",
       "      <td id=\"T_19463_row5_col0\" class=\"data row5 col0\" >0.390761</td>\n",
       "      <td id=\"T_19463_row5_col1\" class=\"data row5 col1\" >0.246708</td>\n",
       "      <td id=\"T_19463_row5_col2\" class=\"data row5 col2\" >0.209387</td>\n",
       "      <td id=\"T_19463_row5_col3\" class=\"data row5 col3\" >0.097590</td>\n",
       "      <td id=\"T_19463_row5_col4\" class=\"data row5 col4\" >0.097590</td>\n",
       "      <td id=\"T_19463_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "      <td id=\"T_19463_row5_col6\" class=\"data row5 col6\" >0.568399</td>\n",
       "      <td id=\"T_19463_row5_col7\" class=\"data row5 col7\" >0.418330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19463_level0_row6\" class=\"row_heading level0 row6\" >ulke_tr</th>\n",
       "      <td id=\"T_19463_row6_col0\" class=\"data row6 col0\" >0.432217</td>\n",
       "      <td id=\"T_19463_row6_col1\" class=\"data row6 col1\" >0.302420</td>\n",
       "      <td id=\"T_19463_row6_col2\" class=\"data row6 col2\" >0.685811</td>\n",
       "      <td id=\"T_19463_row6_col3\" class=\"data row6 col3\" >0.277350</td>\n",
       "      <td id=\"T_19463_row6_col4\" class=\"data row6 col4\" >0.277350</td>\n",
       "      <td id=\"T_19463_row6_col5\" class=\"data row6 col5\" >0.568399</td>\n",
       "      <td id=\"T_19463_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "      <td id=\"T_19463_row6_col7\" class=\"data row6 col7\" >0.509525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19463_level0_row7\" class=\"row_heading level0 row7\" >ulke_us</th>\n",
       "      <td id=\"T_19463_row7_col0\" class=\"data row7 col0\" >0.068487</td>\n",
       "      <td id=\"T_19463_row7_col1\" class=\"data row7 col1\" >0.075849</td>\n",
       "      <td id=\"T_19463_row7_col2\" class=\"data row7 col2\" >0.538132</td>\n",
       "      <td id=\"T_19463_row7_col3\" class=\"data row7 col3\" >0.408248</td>\n",
       "      <td id=\"T_19463_row7_col4\" class=\"data row7 col4\" >0.408248</td>\n",
       "      <td id=\"T_19463_row7_col5\" class=\"data row7 col5\" >0.418330</td>\n",
       "      <td id=\"T_19463_row7_col6\" class=\"data row7 col6\" >0.509525</td>\n",
       "      <td id=\"T_19463_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2def8afed40>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = np.random.RandomState(0)\n",
    "new_df = pd.DataFrame(rs.rand(10,10))\n",
    "\n",
    "corr = normalized_data.loc[:,['boy', 'kilo', 'yas', 'cinsiyet_e', 'cinsiyet_k', 'ulke_fr', 'ulke_tr', 'ulke_us']].corr().abs()\n",
    "\n",
    "corr.style.background_gradient(cmap = 'coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "685dd2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X = standardized_data['kilo']\n",
    "y = standardized_data['boy']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "97f461cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating independent and dependent variable\n",
    "X = standardized_data.iloc[:,1:].values\n",
    "y = standardized_data.iloc[:,0].values\n",
    "#splitting standardized_data into training and testing standardized_data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "db5172d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automating backward elimination technique\n",
    "\n",
    "def DoBackwardElimination(the_regressor, X, y, minP2eliminate):\n",
    "    \n",
    "    assert np.shape(X)[0] == np.shape(y)[0], 'Length of X and y do not match'\n",
    "    assert minP2eliminate > 0, 'Minimum P value to eliminate cannot be zero or negative'\n",
    "    \n",
    "    original_list = list(range(0, np.shape(the_regressor.pvalues)[0]))\n",
    "    \n",
    "    max_p = 10        # Initializing with random value of maximum P value\n",
    "    i = 0\n",
    "    r2adjusted = []   # Will store R Square adjusted value for each loop\n",
    "    r2 = []           # Will store R Square value  for each loop\n",
    "    list_of_originallist = [] # Will store modified index of X at each loop\n",
    "    classifiers_list = [] # fitted classifiers at each loop\n",
    "    \n",
    "    while max_p >= minP2eliminate:\n",
    "        \n",
    "        p_values = list(the_regressor.pvalues)\n",
    "        r2adjusted.append(the_regressor.rsquared_adj)\n",
    "        r2.append(the_regressor.rsquared)\n",
    "        list_of_originallist.append(original_list)\n",
    "        \n",
    "        max_p = max(p_values)\n",
    "        max_p_idx = p_values.index(max_p)\n",
    "        \n",
    "        if max_p_idx == 0:\n",
    "            \n",
    "            temp_p = set(p_values)\n",
    "            \n",
    "            # removing the largest element from temp list\n",
    "            temp_p.remove(max(temp_p))\n",
    "            \n",
    "            max_p = max(temp_p)\n",
    "            max_p_idx = p_values.index(max_p)\n",
    "            \n",
    "            print('Index value 0 found!! Next index value is {}'.format(max_p_idx))\n",
    "            \n",
    "            if max_p < minP2eliminate:\n",
    "                \n",
    "                print('Max P value found less than 0.1 with 0 index ...Loop Ends!!')\n",
    "                \n",
    "                break\n",
    "                \n",
    "        if max_p < minP2eliminate:\n",
    "            \n",
    "            print('Max P value found less than 0.1 without 0 index...Loop Ends!!')\n",
    "            \n",
    "            break\n",
    "        \n",
    "        val_at_idx = original_list[max_p_idx]\n",
    "        \n",
    "        idx_in_org_lst = original_list.index(val_at_idx)\n",
    "        \n",
    "        original_list.remove(val_at_idx)\n",
    "        \n",
    "        print('Popped column index out of original array is {} with P-Value {}'.format(val_at_idx, np.round(np.array(p_values)[max_p_idx], decimals= 4)))\n",
    "        \n",
    "        X_new = X[:, original_list]\n",
    "        \n",
    "        the_regressor = sm.OLS(endog = y, exog = X_new).fit()\n",
    "        classifiers_list.append(the_regressor)\n",
    "        \n",
    "        print('==================================================================================================')\n",
    "        \n",
    "    return classifiers_list, r2, r2adjusted, list_of_originallist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fef080b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.894\n",
      "Model:                            OLS   Adj. R-squared:                  0.836\n",
      "Method:                 Least Squares   F-statistic:                     15.23\n",
      "Date:                Fri, 21 Jul 2023   Prob (F-statistic):           0.000367\n",
      "Time:                        22:49:15   Log-Likelihood:                -4.1158\n",
      "No. Observations:                  15   AIC:                             20.23\n",
      "Df Residuals:                       9   BIC:                             24.48\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.9405      0.235      4.003      0.003       0.409       1.472\n",
      "x2             0.0441      0.172      0.257      0.803      -0.345       0.433\n",
      "x3            -0.2136      0.272     -0.785      0.452      -0.829       0.402\n",
      "x4             0.2333      0.239      0.978      0.354      -0.306       0.773\n",
      "x5             0.3481      0.161      2.166      0.059      -0.016       0.712\n",
      "x6            -0.1270      0.218     -0.582      0.575      -0.621       0.367\n",
      "x7            -0.2014      0.228     -0.885      0.399      -0.716       0.313\n",
      "==============================================================================\n",
      "Omnibus:                        8.152   Durbin-Watson:                   1.209\n",
      "Prob(Omnibus):                  0.017   Jarque-Bera (JB):                4.636\n",
      "Skew:                           1.201   Prob(JB):                       0.0985\n",
      "Kurtosis:                       4.285   Cond. No.                     1.78e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 7.42e-32. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\envs\\notebook\\lib\\site-packages\\scipy\\stats\\_stats_py.py:1772: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=15\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data\n",
    "\n",
    "X = standardized_data.iloc[:, 1:].values         # Selecting all columns except last one that is 'boy'.\n",
    "y = standardized_data['boy'].values\n",
    "\n",
    "# # Adding constant values at start of array X\n",
    "# X = np.append(arr = np.ones((X.shape[0], 1)).astype(int), values=X, axis=1)\n",
    "\n",
    "regressor_SLR_OLS = sm.OLS(endog = y_train, exog = X_train).fit()\n",
    "\n",
    "# Looking at the summary of regressor\n",
    "print(regressor_SLR_OLS.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "69854e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.885\n",
      "Model:                            OLS   Adj. R-squared:                  0.849\n",
      "Method:                 Least Squares   F-statistic:                     24.69\n",
      "Date:                Fri, 21 Jul 2023   Prob (F-statistic):           5.41e-07\n",
      "Time:                        22:51:14   Log-Likelihood:                 18.879\n",
      "No. Observations:                  22   AIC:                            -25.76\n",
      "Df Residuals:                      16   BIC:                            -19.21\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0563      0.040      1.411      0.177      -0.028       0.141\n",
      "x1             1.0160      0.131      7.737      0.000       0.738       1.294\n",
      "x2             0.0550      0.149      0.369      0.717      -0.261       0.371\n",
      "x3            -0.0498      0.047     -1.060      0.305      -0.149       0.050\n",
      "x4             0.1061      0.037      2.887      0.011       0.028       0.184\n",
      "x5             0.0941      0.043      2.198      0.043       0.003       0.185\n",
      "x6             0.0093      0.043      0.214      0.833      -0.083       0.101\n",
      "x7            -0.0471      0.059     -0.795      0.438      -0.173       0.078\n",
      "==============================================================================\n",
      "Omnibus:                        1.031   Durbin-Watson:                   2.759\n",
      "Prob(Omnibus):                  0.597   Jarque-Bera (JB):                0.624\n",
      "Skew:                           0.407   Prob(JB):                        0.732\n",
      "Kurtosis:                       2.863   Cond. No.                     3.46e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.09e-32. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.456\n",
      "Model:                            OLS   Adj. R-squared:                  0.328\n",
      "Method:                 Least Squares   F-statistic:                     3.562\n",
      "Date:                Fri, 21 Jul 2023   Prob (F-statistic):             0.0276\n",
      "Time:                        22:51:14   Log-Likelihood:                 1.7604\n",
      "No. Observations:                  22   AIC:                             6.479\n",
      "Df Residuals:                      17   BIC:                             11.93\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1790      0.077      2.316      0.033       0.016       0.342\n",
      "x1             0.5630      0.283      1.989      0.063      -0.034       1.160\n",
      "x2             0.1986      0.072      2.743      0.014       0.046       0.351\n",
      "x3            -0.0196      0.070     -0.282      0.782      -0.166       0.127\n",
      "x4             0.1649      0.088      1.867      0.079      -0.021       0.351\n",
      "x5            -0.0108      0.091     -0.119      0.907      -0.204       0.182\n",
      "x6             0.0250      0.123      0.202      0.842      -0.235       0.285\n",
      "==============================================================================\n",
      "Omnibus:                        0.221   Durbin-Watson:                   1.359\n",
      "Prob(Omnibus):                  0.895   Jarque-Bera (JB):                0.402\n",
      "Skew:                           0.164   Prob(JB):                        0.818\n",
      "Kurtosis:                       2.425   Cond. No.                     1.99e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.13e-31. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data\n",
    "X = normalized_data.iloc[:, 1:].values\n",
    "y = normalized_data['boy'].values\n",
    "\n",
    "# Adding constant values at the start of array X\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the initial regression model with all predictors\n",
    "regressor_SLR_OLS = sm.OLS(endog=y, exog=X).fit()\n",
    "\n",
    "# Looking at the summary of the initial regressor\n",
    "print(regressor_SLR_OLS.summary())\n",
    "\n",
    "# Remove x2 from the X array\n",
    "X = np.delete(X, 1, axis=1)  # Remove the column associated with x1 (index 1) from X\n",
    "\n",
    "# Fit the new regression model after removing x2\n",
    "regressor_SLR_OLS = sm.OLS(endog=y, exog=X).fit()\n",
    "\n",
    "# Looking at the summary of the updated regressor after removing x3\n",
    "print(regressor_SLR_OLS.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6a501f95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.885\n",
      "Model:                            OLS   Adj. R-squared:                  0.849\n",
      "Method:                 Least Squares   F-statistic:                     24.69\n",
      "Date:                Fri, 21 Jul 2023   Prob (F-statistic):           5.41e-07\n",
      "Time:                        22:51:44   Log-Likelihood:                 18.879\n",
      "No. Observations:                  22   AIC:                            -25.76\n",
      "Df Residuals:                      16   BIC:                            -19.21\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0563      0.040      1.411      0.177      -0.028       0.141\n",
      "x1             1.0160      0.131      7.737      0.000       0.738       1.294\n",
      "x2             0.0550      0.149      0.369      0.717      -0.261       0.371\n",
      "x3            -0.0498      0.047     -1.060      0.305      -0.149       0.050\n",
      "x4             0.1061      0.037      2.887      0.011       0.028       0.184\n",
      "x5             0.0941      0.043      2.198      0.043       0.003       0.185\n",
      "x6             0.0093      0.043      0.214      0.833      -0.083       0.101\n",
      "x7            -0.0471      0.059     -0.795      0.438      -0.173       0.078\n",
      "==============================================================================\n",
      "Omnibus:                        1.031   Durbin-Watson:                   2.759\n",
      "Prob(Omnibus):                  0.597   Jarque-Bera (JB):                0.624\n",
      "Skew:                           0.407   Prob(JB):                        0.732\n",
      "Kurtosis:                       2.863   Cond. No.                     3.46e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.09e-32. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.884\n",
      "Model:                            OLS   Adj. R-squared:                  0.857\n",
      "Method:                 Least Squares   F-statistic:                     32.47\n",
      "Date:                Fri, 21 Jul 2023   Prob (F-statistic):           9.32e-08\n",
      "Time:                        22:51:44   Log-Likelihood:                 18.786\n",
      "No. Observations:                  22   AIC:                            -27.57\n",
      "Df Residuals:                      17   BIC:                            -22.12\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0649      0.032      2.057      0.055      -0.002       0.131\n",
      "x1             1.0373      0.115      9.029      0.000       0.795       1.280\n",
      "x2            -0.0493      0.046     -1.077      0.297      -0.146       0.047\n",
      "x3             0.1141      0.029      3.964      0.001       0.053       0.175\n",
      "x4             0.0986      0.040      2.466      0.025       0.014       0.183\n",
      "x5             0.0018      0.037      0.048      0.962      -0.077       0.081\n",
      "x6            -0.0355      0.049     -0.726      0.478      -0.139       0.068\n",
      "==============================================================================\n",
      "Omnibus:                        0.871   Durbin-Watson:                   2.719\n",
      "Prob(Omnibus):                  0.647   Jarque-Bera (JB):                0.459\n",
      "Skew:                           0.351   Prob(JB):                        0.795\n",
      "Kurtosis:                       2.910   Cond. No.                     2.52e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 7.03e-32. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data\n",
    "X = normalized_data.iloc[:, 1:].values\n",
    "y = normalized_data['boy'].values\n",
    "\n",
    "# Adding constant values at the start of array X\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the initial regression model with all predictors\n",
    "regressor_SLR_OLS = sm.OLS(endog=y, exog=X).fit()\n",
    "\n",
    "# Looking at the summary of the initial regressor\n",
    "print(regressor_SLR_OLS.summary())\n",
    "\n",
    "# Remove x3 from the X array\n",
    "X = np.delete(X, 2, axis=1)  # Remove the column associated with x3 (index 2) from X\n",
    "\n",
    "# Fit the new regression model after removing x2\n",
    "regressor_SLR_OLS = sm.OLS(endog=y, exog=X).fit()\n",
    "\n",
    "# Looking at the summary of the updated regressor after removing x3\n",
    "print(regressor_SLR_OLS.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d25a9e32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.885\n",
      "Model:                            OLS   Adj. R-squared:                  0.849\n",
      "Method:                 Least Squares   F-statistic:                     24.69\n",
      "Date:                Fri, 21 Jul 2023   Prob (F-statistic):           5.41e-07\n",
      "Time:                        22:52:29   Log-Likelihood:                 18.879\n",
      "No. Observations:                  22   AIC:                            -25.76\n",
      "Df Residuals:                      16   BIC:                            -19.21\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0563      0.040      1.411      0.177      -0.028       0.141\n",
      "x1             1.0160      0.131      7.737      0.000       0.738       1.294\n",
      "x2             0.0550      0.149      0.369      0.717      -0.261       0.371\n",
      "x3            -0.0498      0.047     -1.060      0.305      -0.149       0.050\n",
      "x4             0.1061      0.037      2.887      0.011       0.028       0.184\n",
      "x5             0.0941      0.043      2.198      0.043       0.003       0.185\n",
      "x6             0.0093      0.043      0.214      0.833      -0.083       0.101\n",
      "x7            -0.0471      0.059     -0.795      0.438      -0.173       0.078\n",
      "==============================================================================\n",
      "Omnibus:                        1.031   Durbin-Watson:                   2.759\n",
      "Prob(Omnibus):                  0.597   Jarque-Bera (JB):                0.624\n",
      "Skew:                           0.407   Prob(JB):                        0.732\n",
      "Kurtosis:                       2.863   Cond. No.                     3.46e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.09e-32. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.885\n",
      "Model:                            OLS   Adj. R-squared:                  0.849\n",
      "Method:                 Least Squares   F-statistic:                     24.69\n",
      "Date:                Fri, 21 Jul 2023   Prob (F-statistic):           5.41e-07\n",
      "Time:                        22:52:29   Log-Likelihood:                 18.879\n",
      "No. Observations:                  22   AIC:                            -25.76\n",
      "Df Residuals:                      16   BIC:                            -19.21\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1358      0.054      2.522      0.023       0.022       0.250\n",
      "x1             1.0160      0.131      7.737      0.000       0.738       1.294\n",
      "x2             0.0550      0.149      0.369      0.717      -0.261       0.371\n",
      "x3            -0.1559      0.074     -2.098      0.052      -0.313       0.002\n",
      "x4             0.1206      0.046      2.642      0.018       0.024       0.217\n",
      "x5             0.0358      0.044      0.813      0.428      -0.057       0.129\n",
      "x6            -0.0206      0.060     -0.341      0.737      -0.148       0.107\n",
      "==============================================================================\n",
      "Omnibus:                        1.031   Durbin-Watson:                   2.759\n",
      "Prob(Omnibus):                  0.597   Jarque-Bera (JB):                0.624\n",
      "Skew:                           0.407   Prob(JB):                        0.732\n",
      "Kurtosis:                       2.863   Cond. No.                     2.22e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 9.07e-32. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data\n",
    "X = normalized_data.iloc[:, 1:].values\n",
    "y = normalized_data['boy'].values\n",
    "\n",
    "# Adding constant values at the start of array X\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the initial regression model with all predictors\n",
    "regressor_SLR_OLS = sm.OLS(endog=y, exog=X).fit()\n",
    "\n",
    "# Looking at the summary of the initial regressor\n",
    "print(regressor_SLR_OLS.summary())\n",
    "\n",
    "# Remove x5 from the X array\n",
    "X = np.delete(X, 4, axis=1)  # Remove the column associated with x5 (index 4) from X\n",
    "\n",
    "# Fit the new regression model after removing x2\n",
    "regressor_SLR_OLS = sm.OLS(endog=y, exog=X).fit()\n",
    "\n",
    "# Looking at the summary of the updated regressor after removing x3\n",
    "print(regressor_SLR_OLS.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e42445e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.885\n",
      "Model:                            OLS   Adj. R-squared:                  0.849\n",
      "Method:                 Least Squares   F-statistic:                     24.69\n",
      "Date:                Fri, 21 Jul 2023   Prob (F-statistic):           5.41e-07\n",
      "Time:                        22:53:26   Log-Likelihood:                 18.879\n",
      "No. Observations:                  22   AIC:                            -25.76\n",
      "Df Residuals:                      16   BIC:                            -19.21\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0563      0.040      1.411      0.177      -0.028       0.141\n",
      "x1             1.0160      0.131      7.737      0.000       0.738       1.294\n",
      "x2             0.0550      0.149      0.369      0.717      -0.261       0.371\n",
      "x3            -0.0498      0.047     -1.060      0.305      -0.149       0.050\n",
      "x4             0.1061      0.037      2.887      0.011       0.028       0.184\n",
      "x5             0.0941      0.043      2.198      0.043       0.003       0.185\n",
      "x6             0.0093      0.043      0.214      0.833      -0.083       0.101\n",
      "x7            -0.0471      0.059     -0.795      0.438      -0.173       0.078\n",
      "==============================================================================\n",
      "Omnibus:                        1.031   Durbin-Watson:                   2.759\n",
      "Prob(Omnibus):                  0.597   Jarque-Bera (JB):                0.624\n",
      "Skew:                           0.407   Prob(JB):                        0.732\n",
      "Kurtosis:                       2.863   Cond. No.                     3.46e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.09e-32. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.885\n",
      "Model:                            OLS   Adj. R-squared:                  0.849\n",
      "Method:                 Least Squares   F-statistic:                     24.69\n",
      "Date:                Fri, 21 Jul 2023   Prob (F-statistic):           5.41e-07\n",
      "Time:                        22:53:26   Log-Likelihood:                 18.879\n",
      "No. Observations:                  22   AIC:                            -25.76\n",
      "Df Residuals:                      16   BIC:                            -19.21\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.0160      0.131      7.737      0.000       0.738       1.294\n",
      "x2             0.0550      0.149      0.369      0.717      -0.261       0.371\n",
      "x3            -0.0160      0.065     -0.246      0.809      -0.154       0.122\n",
      "x4             0.1398      0.049      2.876      0.011       0.037       0.243\n",
      "x5             0.1166      0.052      2.226      0.041       0.006       0.228\n",
      "x6             0.0318      0.038      0.838      0.415      -0.049       0.112\n",
      "x7            -0.0246      0.071     -0.345      0.734      -0.175       0.126\n",
      "==============================================================================\n",
      "Omnibus:                        1.031   Durbin-Watson:                   2.759\n",
      "Prob(Omnibus):                  0.597   Jarque-Bera (JB):                0.624\n",
      "Skew:                           0.407   Prob(JB):                        0.732\n",
      "Kurtosis:                       2.863   Cond. No.                     1.36e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.47e-31. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data\n",
    "X = normalized_data.iloc[:, 1:].values\n",
    "y = normalized_data['boy'].values\n",
    "\n",
    "# Adding constant values at the start of array X\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the initial regression model with all predictors\n",
    "regressor_SLR_OLS = sm.OLS(endog=y, exog=X).fit()\n",
    "\n",
    "# Looking at the summary of the initial regressor\n",
    "print(regressor_SLR_OLS.summary())\n",
    "\n",
    "# Remove x1 from the X array\n",
    "X = np.delete(X, 0, axis=1)  # Remove the column associated with x1 (index 0) from X\n",
    "\n",
    "# Fit the new regression model after removing x2\n",
    "regressor_SLR_OLS = sm.OLS(endog=y, exog=X).fit()\n",
    "\n",
    "# Looking at the summary of the updated regressor after removing x3\n",
    "print(regressor_SLR_OLS.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afee1f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6680d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "## devamı kopyala yapıştır işte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220ac8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5bb470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81fe7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e20aebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
